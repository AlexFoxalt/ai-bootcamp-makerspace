{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Skip restarting message in Colab\n",
    "import sys; modules = list(sys.modules.keys())\n",
    "for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
    "\n",
    "!pip install \"unsloth==2025.2.12\" vllm\n",
    "!pip install --upgrade pillow\n",
    "# If you are running this notebook on local, you need to install `diffusers` too\n",
    "# !pip install diffusers\n",
    "# Temporarily install a specific TRL nightly version\n",
    "!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"open-r1/OpenR1-Math-Raw\")"
   ],
   "id": "278f648ba5b5660f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reduce the size of training set so the script won't run forever\n",
    "print(\"Before\", len(ds[\"train\"]))\n",
    "ds[\"train\"] = ds[\"train\"].select(range(10_000))\n",
    "print(\"After\", len(ds[\"train\"]))"
   ],
   "id": "526d0e26ea84475a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from unsloth import FastLanguageModel, PatchFastRL\n",
    "\n",
    "PatchFastRL(\"GRPO\", FastLanguageModel)"
   ],
   "id": "dac90e8a36744097"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from unsloth import is_bfloat16_supported\n",
    "import torch\n",
    "max_seq_length = 512 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    random_state = 3407,\n",
    ")"
   ],
   "id": "ec69f617cfd37b0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "Respond in the following JSON format:\n",
    "{\n",
    "  \"reasoning\": \"Chain of thought to achieve the goal\",\n",
    "  \"answer\": \"Final answer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def format_to_json(reasoning: str, answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Just replace placeholders to create JSON formatted string\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"reasoning\": reasoning,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "    return json.dumps(result)\n",
    "\n",
    "def get_questions(dataset, split=\"train\") -> Dataset:\n",
    "    \"\"\"\n",
    "    Processes each item of dataset.\n",
    "\n",
    "    For each problem in the dataset:\n",
    "    1. Creates a prompt with two messages:\n",
    "       - A system message containing the response formatting instructions.\n",
    "       - A user message containing the question.\n",
    "    2. Extracts the answer using the 'format_to_json' function.\n",
    "\n",
    "    Returns:\n",
    "        The processed dataset with each entry containing the formatted prompt and extracted answer.\n",
    "    \"\"\"\n",
    "    data = dataset[split]\n",
    "    result: list[dict] = []\n",
    "    for item in tqdm(data):\n",
    "        if not item[\"answer\"]:\n",
    "          continue\n",
    "        result.append(\n",
    "            {\n",
    "                \"question\": item[\"problem\"],\n",
    "                \"prompt\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": item[\"problem\"]},\n",
    "                ],\n",
    "                \"answer\": item[\"answer\"],\n",
    "            }\n",
    "        )\n",
    "    # list of dicts to dataset\n",
    "    return Dataset.from_pandas(pd.DataFrame(data=result))"
   ],
   "id": "649d5aaffd6871eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = get_questions(ds)",
   "id": "4c023d04aed194b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(dataset[0])"
   ],
   "id": "7355153f908fccfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Reward function for checking strict JSON format adherence\n",
    "def strict_json_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Rewards responses that strictly follow the required JSON format with \"reasoning\" and \"answer\" fields.\n",
    "\n",
    "    Steps:\n",
    "    - Attempts to parse the response as JSON.\n",
    "    - Checks if the JSON contains exactly two keys: \"reasoning\" and \"answer\".\n",
    "    - Returns a reward of 1.0 if the format is correct, otherwise 0.0.\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    scores = []\n",
    "    for response in responses:\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            if isinstance(parsed, dict) and list(parsed.keys()) == [\"reasoning\", \"answer\"]:\n",
    "                scores.append(1.0)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "        except json.JSONDecodeError:\n",
    "            scores.append(0.0)\n",
    "    return scores\n",
    "\n",
    "# Reward function for correctness of answer\n",
    "def correctness_json_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Rewards responses that provide the correct answer.\n",
    "\n",
    "    Steps:\n",
    "    - Extracts the \"answer\" field from the JSON response.\n",
    "    - Compares it to the expected answer.\n",
    "    - Assigns a reward of 2.0 if the answer is correct, otherwise 0.0.\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    extracted_answers = []\n",
    "    # parsed_answers = [json.loads(a)[\"answer\"] for a in answer]\n",
    "\n",
    "    for response in responses:\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            extracted_answers.append(str(parsed.get(\"answer\", \"\")).strip())\n",
    "        except json.JSONDecodeError:\n",
    "            extracted_answers.append(\"\")\n",
    "\n",
    "    return [2.0 if str(r) == str(a) else 0.0 for r, a in zip(extracted_answers, answer)]\n",
    "\n",
    "# Reward function for reasoning quality\n",
    "def reasoning_length_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Rewards responses that provide a sufficiently detailed reasoning section.\n",
    "\n",
    "    Steps:\n",
    "    - Extracts the \"reasoning\" field from the JSON response.\n",
    "    - Measures its length and assigns a reward based on the number of words.\n",
    "    - Rewards 1.0 for at least 10 words, with a max of 1.5 for 30+ words.\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    scores = []\n",
    "\n",
    "    for response in responses:\n",
    "        try:\n",
    "            parsed = json.loads(response)\n",
    "            reasoning = parsed.get(\"reasoning\", \"\").strip()\n",
    "            word_count = len(reasoning.split())\n",
    "            if word_count >= 30:\n",
    "                scores.append(1.5)\n",
    "            elif word_count >= 10:\n",
    "                scores.append(1.0)\n",
    "            else:\n",
    "                scores.append(0.5 if word_count > 0 else 0.0)\n",
    "        except json.JSONDecodeError:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Reward function for JSON validity\n",
    "def valid_json_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Rewards responses that are valid JSON regardless of content accuracy.\n",
    "\n",
    "    Steps:\n",
    "    - Attempts to parse the response as JSON.\n",
    "    - Returns 1.0 if valid JSON, otherwise 0.0.\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    return [1.0 if is_valid_json(r) else 0.0 for r in responses]\n",
    "\n",
    "def is_valid_json(text: str) -> bool:\n",
    "    \"\"\"Helper function to check if a string is valid JSON.\"\"\"\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return True\n",
    "    except json.JSONDecodeError:\n",
    "        return False\n",
    "\n",
    "# Reward function for penalizing extra content\n",
    "def no_extra_content_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Rewards responses that contain only JSON and no extra text.\n",
    "\n",
    "    Steps:\n",
    "    - Uses regex to check if the response starts and ends with a valid JSON object.\n",
    "    - Returns 1.0 if there's no extra content, otherwise 0.0.\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    pattern = r'^\\s*\\{.*\\}\\s*$'\n",
    "    return [1.0 if re.match(pattern, r, re.DOTALL) else 0.0 for r in responses]\n"
   ],
   "id": "c417ac2b8fe98ebc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True, # use vLLM for fast inference!\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 3, # Decrease if out of memory\n",
    "    max_prompt_length = 256,\n",
    "    max_completion_length = 200,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 250,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ],
   "id": "5a98b8440a34bc3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        strict_json_format_reward_func,\n",
    "        correctness_json_reward_func,\n",
    "        reasoning_length_reward_func,\n",
    "        valid_json_reward_func,\n",
    "        no_extra_content_reward_func,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "632808b51e525930"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
