{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJXW_DgiSebM"
   },
   "source": [
    "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
    "\n",
    "In the following notebook we'll complete the following tasks:\n",
    "\n",
    "- ü§ù Breakout Room #1:\n",
    "  1. Install required libraries\n",
    "  2. Set Environment Variables\n",
    "  3. Creating our Tool Belt\n",
    "  4. Creating Our State\n",
    "  5. Creating and Compiling A Graph!\n",
    "\n",
    "  - ü§ù Breakout Room #2:\n",
    "  1. Evaluating the LangGraph Application with LangSmith\n",
    "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
    "  3. LangGraph for the \"Patterns\" of GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djQ3nRAgoF67"
   },
   "source": [
    "# ü§ù Breakout Room #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7pQDUhUnIo8"
   },
   "source": [
    "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
    "\n",
    "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
    "\n",
    "### Why Cycles?\n",
    "\n",
    "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
    "\n",
    "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
    "\n",
    "### Why LangGraph?\n",
    "\n",
    "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_fLDElOVoop"
   },
   "source": [
    "## Task 1:  Dependencies\n",
    "\n",
    "We'll first install all our required libraries.\n",
    "\n",
    "> NOTE: If you're running this locally - please skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaVwN269EttM",
    "outputId": "ba50f775-3957-4d88-9a88-43acc6966dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m145.8/145.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain_openai langchain-community langgraph arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wujPjGJuoPwg"
   },
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We'll want to set both our OpenAI API key and our LangSmith environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jdh8CoVWHRvs",
    "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBRyQmEAVzua"
   },
   "source": [
    "## Task 3: Creating our Tool Belt\n",
    "\n",
    "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
    "\n",
    "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/tools) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
    "\n",
    "We'll leverage:\n",
    "\n",
    "- [Tavily Search Results](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
    "- [Arxiv](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/tools/arxiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k6n_Dob2F46"
   },
   "source": [
    "####üèóÔ∏è Activity #1:\n",
    "\n",
    "Please add the tools to use into our toolbelt.\n",
    "\n",
    "> NOTE: Each tool in our toolbelt should be a method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lAxaSvlfIeOg"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "tool_belt = [\n",
    "    tavily_tool,\n",
    "    ArxivQueryRun(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VI-C669ZYVI5"
   },
   "source": [
    "### Model\n",
    "\n",
    "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
    "\n",
    "- OpenAI's GPT-3.5 and GPT-4\n",
    "- Anthropic's Claude\n",
    "- Google's Gemini\n",
    "\n",
    "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QkNS8rNZJs4z"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ugkj3GzuZpQv"
   },
   "source": [
    "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4OdMqFafZ_0V"
   },
   "outputs": [],
   "source": [
    "model = model.bind_tools(tool_belt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERzuGo6W18Lr"
   },
   "source": [
    "#### ‚ùì Question #1:\n",
    "\n",
    "How does the model determine which tool to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_296Ub96Z_H8"
   },
   "source": [
    "## Task 4: Putting the State in Stateful\n",
    "\n",
    "Earlier we used this phrasing:\n",
    "\n",
    "`coordinated multi-actor and stateful applications`\n",
    "\n",
    "So what does that \"stateful\" mean?\n",
    "\n",
    "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
    "\n",
    "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
    "\n",
    "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
    "\n",
    "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
    "\n",
    "1. We initialize our state object:\n",
    "  - `{\"messages\" : []}`\n",
    "2. Our user submits a query to our application.\n",
    "  - New State: `HumanMessage(#1)`\n",
    "  - `{\"messages\" : [HumanMessage(#1)}`\n",
    "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
    "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
    "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
    "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mxL9b_NZKUdL"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWsMhfO9grLu"
   },
   "source": [
    "## Task 5: It's Graphing Time!\n",
    "\n",
    "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
    "\n",
    "Let's take a second to refresh ourselves about what a graph is in this context.\n",
    "\n",
    "Graphs, also called networks in some circles, are a collection of connected objects.\n",
    "\n",
    "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
    "\n",
    "Let's look at a simple graph.\n",
    "\n",
    "![image](https://i.imgur.com/2NFLnIc.png)\n",
    "\n",
    "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
    "\n",
    "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
    "\n",
    "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
    "\n",
    "Let's create some nodes and expand on our diagram.\n",
    "\n",
    "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "91flJWtZLUrl"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def call_model(state):\n",
    "  messages = state[\"messages\"]\n",
    "  response = model.invoke(messages)\n",
    "  return {\"messages\" : [response]}\n",
    "\n",
    "tool_node = ToolNode(tool_belt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bwR7MgWj3Wg"
   },
   "source": [
    "Now we have two total nodes. We have:\n",
    "\n",
    "- `call_model` is a node that will...well...call the model\n",
    "- `tool_node` is a node which can call a tool\n",
    "\n",
    "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vF4_lgtmQNo",
    "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11b3512b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "uncompiled_graph = StateGraph(AgentState)\n",
    "\n",
    "uncompiled_graph.add_node(\"agent\", call_model)\n",
    "uncompiled_graph.add_node(\"action\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8CjRlbVmRpW"
   },
   "source": [
    "Let's look at what we have so far:\n",
    "\n",
    "![image](https://i.imgur.com/md7inqG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaXHpPeSnOWC"
   },
   "source": [
    "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGCbaYqRnmiw",
    "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11b3512b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompiled_graph.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUsfGoSpoF9U"
   },
   "source": [
    "![image](https://i.imgur.com/wNixpJe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q_pQgHmoW0M"
   },
   "source": [
    "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
    "\n",
    "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
    "\n",
    "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
    "\n",
    "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
    "\n",
    "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BZgb81VQf9o",
    "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11b3512b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"action\"\n",
    "\n",
    "  return END\n",
    "\n",
    "uncompiled_graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Cvhcf4jp0Ce"
   },
   "source": [
    "Let's visualize what this looks like.\n",
    "\n",
    "![image](https://i.imgur.com/8ZNwKI5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKCjWJCkrJb9"
   },
   "source": [
    "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvcgbHf1rIXZ",
    "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11b3512b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompiled_graph.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiWDwBQtrw7Z"
   },
   "source": [
    "Let's look at the final visualization.\n",
    "\n",
    "![image](https://i.imgur.com/NWO7usO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYqDpErlsCsu"
   },
   "source": [
    "All that's left to do now is to compile our workflow - and we're off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zt9-KS8DpzNx"
   },
   "outputs": [],
   "source": [
    "compiled_graph = uncompiled_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhNWIwBL1W4Q"
   },
   "source": [
    "#### ‚ùì Question #2:\n",
    "\n",
    "Is there any specific limit to how many times we can cycle?\n",
    "\n",
    "If not, how could we impose a limit to the number of cycles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEYcTShCsPaa"
   },
   "source": [
    "## Using Our Graph\n",
    "\n",
    "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
    "\n",
    "Let's try out a few examples to see how it fairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn4n37PQRPII",
    "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_s3SX0BTgPpF85loed4p7hIt5', 'function': {'arguments': '{\"query\":\"current captain of the Winnipeg Jets 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 162, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-77f82d17-4536-461c-a54c-5498fe624436-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current captain of the Winnipeg Jets 2023'}, 'id': 'call_s3SX0BTgPpF85loed4p7hIt5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 27, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "[ToolMessage(content='[{\"url\": \"https://thehockeynews.com/nhl/winnipeg-jets/news/jets-name-adam-lowry-as-team-captain\", \"content\": \"Jets Name Adam Lowry as Team Captain - The Hockey News Winnipeg Jets News, Analysis and More My Account Subscriptions Jets Name Adam Lowry as Team Captain The Winnipeg Jets will have a captain for the 2023-24 season. After going captain-less in 2022-23, the Winnipeg Jets unveiled Adam Lowry as the club\\'s new captain on Tuesday morning. Having stripped Wheeler of the \\'C\\' upon joining the Jets last season, head coach Rick Bowness rolled with three alternates in 2022-23, as Lowry, Josh Morrissey and Mark Scheifele each served in leadership roles with the club. Although it will be his first time serving as a team captain since his final year with the Swift Current Broncos in 2012-13, Lowry won\\'t need to look far for leadership examples.\"}, {\"url\": \"https://thehockeynews.com/news/winnipeg-jets-name-adam-lowry-captain\", \"content\": \"Winnipeg Jets Name Adam Lowry Captain - The Hockey News Winnipeg Jets Name Adam Lowry Captain The Winnipeg Jets have named Adam Lowry the third captain in franchise history. Lowry becomes the third captain in Jets franchise history and takes over the role after Blake Wheeler served in it for six years before being stripped of the captaincy prior to the 2022-23 season. The 30-year-old Lowry has spent his entire nine-year NHL career with the Jets, logging 621 regular-season games with the franchise and racking up 93 goals and 111 assists for 204 points in the process. That is the question facing the Canadiens, Red Wings, Bruins, Canucks and six other squads as NHL trade deadline season kicks into gear.\"}, {\"url\": \"https://winnipeg.citynews.ca/2023/09/12/winnipeg-jets-adam-lowry-captain/\", \"content\": \"Winnipeg Jets name Adam Lowry captain | CityNews Winnipeg Jets make Adam Lowry new captain, third to wear ‚ÄòC‚Äô in Winnipeg history Winnipeg Jets centre Adam Lowry. Centre Adam Lowry was named the Winnipeg Jets new captain on Tuesday. Lowry is the third Jets captain since the team moved from Atlanta to Winnipeg in 2011. Watch CityNews Winnipeg, and get up-to-the-minute breaking-news alerts, traffic, weather and video from CityNews anywhere you are ‚Äì across all Android and iOS devices. These cookies and data are essential for browsing our website and allowing services. These cookies and data enable the website to provide enhanced functionality and personalized content. These cookies may track data across websites for marketing and interest-based advertising to provide personalized content, offers, and advertisements.\"}, {\"url\": \"https://globalnews.ca/news/9954570/winnipeg-jets-adam-lowry-captain/\", \"content\": \"Lowry, 30, becomes the third captain in Jets 2.0 history, following in the footsteps of Andrew Ladd, who announced his retirement from hockey on Sunday, and Blake Wheeler.\"}, {\"url\": \"https://www.cbc.ca/news/canada/manitoba/adam-lowry-captain-winnipeg-jets-1.6963881\", \"content\": \"Adam Lowry named new captain of Winnipeg Jets | CBC News About CBC News Adam Lowry named new captain of Winnipeg Jets | CBC News Loaded Adam Lowry named new captain of Winnipeg Jets The Winnipeg Jets have a new leader, one year after stripping the C from Blake Wheeler and deciding to play without a captain. Adam Lowry, seen celebrating a goal against the Los Angeles Kings last season, has been named the new captain for the Winnipeg Jets. Adam Lowry,\\xa0who has been a Jet\\xa0since 2011\\xa0when he was drafted 67th\\xa0overall, is the new captain of the NHL team\\xa0‚Äî its third since relocating to Winnipeg from Atlanta in 2011. About CBC\"}]', name='tavily_search_results_json', id='466a3430-b880-47f3-8f12-185e2d1cb2c9', tool_call_id='call_s3SX0BTgPpF85loed4p7hIt5', artifact={'query': 'current captain of the Winnipeg Jets 2023', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Jets Name Adam Lowry as Team Captain - The Hockey News', 'url': 'https://thehockeynews.com/nhl/winnipeg-jets/news/jets-name-adam-lowry-as-team-captain', 'content': \"Jets Name Adam Lowry as Team Captain - The Hockey News Winnipeg Jets News, Analysis and More My Account Subscriptions Jets Name Adam Lowry as Team Captain The Winnipeg Jets will have a captain for the 2023-24 season. After going captain-less in 2022-23, the Winnipeg Jets unveiled Adam Lowry as the club's new captain on Tuesday morning. Having stripped Wheeler of the 'C' upon joining the Jets last season, head coach Rick Bowness rolled with three alternates in 2022-23, as Lowry, Josh Morrissey and Mark Scheifele each served in leadership roles with the club. Although it will be his first time serving as a team captain since his final year with the Swift Current Broncos in 2012-13, Lowry won't need to look far for leadership examples.\", 'score': 0.9227683, 'raw_content': None}, {'title': 'Winnipeg Jets Name Adam Lowry Captain - The Hockey News', 'url': 'https://thehockeynews.com/news/winnipeg-jets-name-adam-lowry-captain', 'content': 'Winnipeg Jets Name Adam Lowry Captain - The Hockey News Winnipeg Jets Name Adam Lowry Captain The Winnipeg Jets have named Adam Lowry the third captain in franchise history. Lowry becomes the third captain in Jets franchise history and takes over the role after Blake Wheeler served in it for six years before being stripped of the captaincy prior to the 2022-23 season. The 30-year-old Lowry has spent his entire nine-year NHL career with the Jets, logging 621 regular-season games with the franchise and racking up 93 goals and 111 assists for 204 points in the process. That is the question facing the Canadiens, Red Wings, Bruins, Canucks and six other squads as NHL trade deadline season kicks into gear.', 'score': 0.8708723, 'raw_content': None}, {'title': 'Winnipeg Jets name Adam Lowry captain | CityNews Winnipeg', 'url': 'https://winnipeg.citynews.ca/2023/09/12/winnipeg-jets-adam-lowry-captain/', 'content': 'Winnipeg Jets name Adam Lowry captain | CityNews Winnipeg Jets make Adam Lowry new captain, third to wear ‚ÄòC‚Äô in Winnipeg history Winnipeg Jets centre Adam Lowry. Centre Adam Lowry was named the Winnipeg Jets new captain on Tuesday. Lowry is the third Jets captain since the team moved from Atlanta to Winnipeg in 2011. Watch CityNews Winnipeg, and get up-to-the-minute breaking-news alerts, traffic, weather and video from CityNews anywhere you are ‚Äì across all Android and iOS devices. These cookies and data are essential for browsing our website and allowing services. These cookies and data enable the website to provide enhanced functionality and personalized content. These cookies may track data across websites for marketing and interest-based advertising to provide personalized content, offers, and advertisements.', 'score': 0.75723875, 'raw_content': None}, {'title': 'Winnipeg Jets announce Adam Lowry as new captain - Global News', 'url': 'https://globalnews.ca/news/9954570/winnipeg-jets-adam-lowry-captain/', 'content': 'Lowry, 30, becomes the third captain in Jets 2.0 history, following in the footsteps of Andrew Ladd, who announced his retirement from hockey on Sunday, and Blake Wheeler.', 'score': 0.740494, 'raw_content': None}, {'title': 'Adam Lowry named new captain of Winnipeg Jets - CBC.ca', 'url': 'https://www.cbc.ca/news/canada/manitoba/adam-lowry-captain-winnipeg-jets-1.6963881', 'content': 'Adam Lowry named new captain of Winnipeg Jets | CBC News About CBC News Adam Lowry named new captain of Winnipeg Jets | CBC News Loaded Adam Lowry named new captain of Winnipeg Jets The Winnipeg Jets have a new leader, one year after stripping the C from Blake Wheeler and deciding to play without a captain. Adam Lowry, seen celebrating a goal against the Los Angeles Kings last season, has been named the new captain for the Winnipeg Jets. Adam Lowry,\\xa0who has been a Jet\\xa0since 2011\\xa0when he was drafted 67th\\xa0overall, is the new captain of the NHL team\\xa0‚Äî its third since relocating to Winnipeg from Atlanta in 2011. About CBC', 'score': 0.7274535, 'raw_content': None}], 'response_time': 1.72})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content=\"The current captain of the Winnipeg Jets is Adam Lowry. He was named the team's captain for the 2023-24 season, becoming the third captain in the franchise's history since relocating to Winnipeg.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 1036, 'total_tokens': 1079, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-afd91d23-e607-46ab-9c93-7aaa6805da68-0', usage_metadata={'input_tokens': 1036, 'output_tokens': 43, 'total_tokens': 1079, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Session end time 2025-02-01 07:54:17.496397+00:00 is before run start time 2025-02-01 07:54:18.484467\"}')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\" : [HumanMessage(content=\"Who is the current captain of the Winnipeg Jets?\")]}\n",
    "\n",
    "async for chunk in compiled_graph.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBHnUtLSscRr"
   },
   "source": [
    "Let's look at what happened:\n",
    "\n",
    "1. Our state object was populated with our request\n",
    "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
    "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
    "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
    "5. The agent node added a response to the state object and passed it along the conditional edge\n",
    "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
    "\n",
    "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afv2BuEsV5JG",
    "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BTXvUKQScd8PoC8xCSnhgczK', 'function': {'arguments': '{\"query\":\"constraining baryonic feedback matter power spectrum fast radio bursts\"}', 'name': 'arxiv'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 173, 'total_tokens': 199, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ce4c7156-7f5b-4575-af03-8e3849936ef4-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'constraining baryonic feedback matter power spectrum fast radio bursts'}, 'id': 'call_BTXvUKQScd8PoC8xCSnhgczK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 173, 'output_tokens': 26, 'total_tokens': 199, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "Tool Used: arxiv\n",
      "[ToolMessage(content='Published: 2025-01-29\\nTitle: Constraining the Effect of Baryonic Feedback on the Matter Power Spectrum with Fast Radio Bursts\\nAuthors: Isabel Medlock, Daisuke Nagai, Daniel Angl√©s Alc√°zar, Matthew Gebhardt\\nSummary: In the age of large-scale galaxy and lensing surveys, such as DESI, Euclid,\\nRoman and Rubin, we stand poised to usher in a transformative new phase of\\ndata-driven cosmology. To fully harness the capabilities of these surveys, it\\nis critical to constrain the poorly understood influence of baryon feedback\\nphysics on the matter power spectrum. We investigate the use of a powerful and\\nnovel cosmological probe - fast radio bursts (FRBs) - to capture baryonic\\neffects on the matter power spectrum, leveraging simulations from the CAMELS\\nprojects, including IllustrisTNG, SIMBA, and Astrid. We find that FRB\\nstatistics exhibit a strong correlation, independet of the subgrid model and\\ncosmology, with quantities known to encapsulate baryonic impacts on the matter\\npower spectrum, such as baryon spread and the halo baryon fraction. We propose\\nan innovative method utilizing FRB observations to quantify the effects of\\nfeedback physics and enhance weak lensing measurements of $S_{8}$. We outline\\nthe necessary steps to prepare for the imminent detection of large FRB\\npopulations in the coming years, focusing on understanding the redshift\\nevolution of FRB observables and mitigating the effects of cosmic variance.\\n\\nPublished: 2024-12-12\\nTitle: Calibrating baryonic feedback with weak lensing and fast radio bursts\\nAuthors: Robert Reischke, Dennis Neumann, Klara Antonia Bertmann, Steffen Hagstotz, Hendrik Hildebrandt\\nSummary: One of the key limitations of large-scale structure surveys of the current\\nand future generation, such as Euclid, LSST-Rubin or Roman, is the influence of\\nfeedback processes on the distribution of matter in the Universe. This effect,\\ncalled baryonic feedback, modifies the matter power spectrum on non-linear\\nscales much stronger than any cosmological parameter of interest. Constraining\\nthese modifications is therefore key to unlock the full potential of the\\nupcoming surveys, and we propose to do so with the help of Fast Radio Bursts\\n(FRBs). FRBs are short, astrophysical radio transients of extragalactic origin.\\nTheir burst signal is dispersed by the free electrons in the\\nlarge-scale-structure, leading to delayed arrival times at different\\nfrequencies characterised by the dispersion measure (DM). Since the dispersion\\nmeasure is sensitive to the integrated line-of-sight electron density, it is a\\ndirect probe of the baryonic content of the Universe. We investigate how FRBs\\ncan break the degeneracies between cosmological and feedback parameters by\\ncorrelating the observed Dispersion Measure with the weak gravitational lensing\\nsignal of a Euclid-like survey. In particular we use a simple one-parameter\\nmodel controlling baryonic feedback, but we expect similar findings for more\\ncomplex models. Within this model we find that $\\\\sim 10^4$ FRBs are sufficient\\nto constrain the baryonic feedback 10 times better than cosmic shear alone.\\nBreaking this degeneracy will tighten the constraints considerably, for example\\nwe expect a factor of two improvement on the sum of neutrino masses\\n\\nPublished: 2022-01-11\\nTitle: Breaking baryon-cosmology degeneracy with the electron density power spectrum\\nAuthors: Andrina Nicola, Francisco Villaescusa-Navarro, David N. Spergel, Jo Dunkley, Daniel Angl√©s-Alc√°zar, Romeel Dav√©, Shy Genel, Lars Hernquist, Daisuke Nagai, Rachel S. Somerville, Benjamin D. Wandelt\\nSummary: Uncertain feedback processes in galaxies affect the distribution of matter,\\ncurrently limiting the power of weak lensing surveys. If we can identify\\ncosmological statistics that are robust against these uncertainties, or\\nconstrain these effects by other means, then we can enhance the power of\\ncurrent and upcoming observations from weak lensing surveys such as DES,\\nEuclid, the Rubin Observatory, and the Roman Space Telescope. In this work,', name='arxiv', id='c9d27dd7-286e-491b-ad6b-f3f1fac78190', tool_call_id='call_BTXvUKQScd8PoC8xCSnhgczK')]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content=\"Recent research has focused on constraining the effects of baryonic feedback on the matter power spectrum using fast radio bursts (FRBs). Here are some key insights from the relevant studies:\\n\\n1. **Baryonic Feedback and Matter Power Spectrum**:\\n   - Baryonic feedback refers to the processes by which baryonic matter (normal matter) interacts with dark matter in the universe, affecting the distribution of matter on various scales. This feedback can significantly modify the matter power spectrum, particularly on non-linear scales, which poses challenges for cosmological surveys.\\n\\n2. **Role of Fast Radio Bursts (FRBs)**:\\n   - FRBs are brief, intense bursts of radio waves from extragalactic sources. Their signals are dispersed by free electrons in the universe, leading to a measurable delay in arrival times at different frequencies, characterized by the dispersion measure (DM). This DM is sensitive to the integrated electron density along the line of sight, making FRBs a valuable tool for probing baryonic content.\\n\\n3. **Correlation with Baryonic Effects**:\\n   - Studies have shown that FRB statistics correlate strongly with quantities that encapsulate baryonic impacts on the matter power spectrum, such as baryon spread and halo baryon fraction. This correlation is independent of the specific subgrid models and cosmological parameters used in simulations.\\n\\n4. **Innovative Methods for Measurement**:\\n   - Researchers propose using FRB observations to quantify the effects of baryonic feedback and improve weak lensing measurements of cosmological parameters, such as \\\\(S_8\\\\). By correlating the observed DM of FRBs with weak gravitational lensing signals, it is possible to break degeneracies between cosmological and feedback parameters.\\n\\n5. **Future Prospects**:\\n   - The studies suggest that a relatively small number of FRBs (around \\\\(10^4\\\\)) could significantly enhance the constraints on baryonic feedback, improving measurements by an order of magnitude compared to cosmic shear alone. This could lead to tighter constraints on fundamental parameters, such as the sum of neutrino masses.\\n\\n6. **Preparation for Large FRB Populations**:\\n   - As large populations of FRBs are expected to be detected in the coming years, understanding the redshift evolution of FRB observables and mitigating cosmic variance will be crucial for leveraging FRBs in cosmological studies.\\n\\nThese findings highlight the potential of FRBs as a novel cosmological probe to address the challenges posed by baryonic feedback in understanding the universe's structure and evolution.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 1090, 'total_tokens': 1590, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-c032c249-680e-477e-84af-9b6376b2dcf8-0', usage_metadata={'input_tokens': 1090, 'output_tokens': 500, 'total_tokens': 1590, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"Tell me more about constraining the effect of baryonic feedback on the matter power spectrum with fast radio bursts\")]}\n",
    "\n",
    "async for chunk in compiled_graph.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        if node == \"action\":\n",
    "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
    "        print(values[\"messages\"])\n",
    "\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXzDlZVz1Hnf"
   },
   "source": [
    "####üèóÔ∏è Activity #2:\n",
    "\n",
    "Please write out the steps the agent took to arrive at the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7c8-Uyarh1v"
   },
   "source": [
    "## Part 1: LangSmith Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV3XeFOT1Sar"
   },
   "source": [
    "### Pre-processing for LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wruQCuzewUuO"
   },
   "source": [
    "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oeXdQgbxwhTv"
   },
   "outputs": [],
   "source": [
    "def convert_inputs(input_object):\n",
    "  return {\"messages\" : [HumanMessage(content=input_object[\"question\"])]}\n",
    "\n",
    "def parse_output(input_state):\n",
    "  return input_state[\"messages\"][-1].content\n",
    "\n",
    "agent_chain = convert_inputs | compiled_graph | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "orYxBZXSxJjZ",
    "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Building a whimsical project like a \"red car inside a tree with little hands that shakes a helicopter\" sounds like a fun and creative endeavor! Here‚Äôs a playful recipe to guide you through this imaginative construction:\\n\\n### Materials Needed:\\n1. **For the Tree:**\\n   - Cardboard or foam board (for the tree trunk and branches)\\n   - Green construction paper or felt (for leaves)\\n   - Brown paint or markers (for the trunk)\\n   - Scissors\\n   - Hot glue gun or craft glue\\n\\n2. **For the Red Car:**\\n   - Red cardboard or paper (for the car body)\\n   - Small wheels (can be made from bottle caps or cardboard circles)\\n   - Markers or stickers (for car details)\\n   - Glue\\n\\n3. **For the Little Hands:**\\n   - Small paper or felt (to create hands)\\n   - Googly eyes (optional, for added fun)\\n   - Pipe cleaners (for arms)\\n   - Glue\\n\\n4. **For the Helicopter:**\\n   - Small plastic or paper helicopter (or make one from cardboard)\\n   - String or thin wire (to attach the helicopter)\\n   - A small motor or a simple mechanism (to create shaking motion)\\n\\n### Instructions:\\n\\n1. **Build the Tree:**\\n   - Cut a large piece of cardboard into a tree trunk shape and paint it brown.\\n   - Create branches by cutting smaller pieces of cardboard and attaching them to the trunk.\\n   - Cut out leaf shapes from green paper and glue them onto the branches.\\n\\n2. **Create the Red Car:**\\n   - Cut out a car shape from red cardboard. Make it as simple or detailed as you like.\\n   - Attach wheels to the bottom of the car using glue. Ensure they can spin freely.\\n   - Add details to the car using markers or stickers.\\n\\n3. **Make the Little Hands:**\\n   - Cut out small hand shapes from paper or felt.\\n   - Attach them to the ends of pipe cleaners to create arms.\\n   - Optionally, add googly eyes to the hands for a fun touch.\\n\\n4. **Assemble the Scene:**\\n   - Place the red car inside the tree, either on a branch or at the base.\\n   - Position the little hands around the car, as if they are reaching for it or playing with it.\\n\\n5. **Create the Helicopter:**\\n   - If using a small plastic helicopter, attach it to the top of the tree using string or wire.\\n   - If making a helicopter from cardboard, cut out the body and rotor blades, then assemble them.\\n   - Attach a small motor or mechanism to make the helicopter shake. This could be a simple battery-operated motor that vibrates.\\n\\n6. **Final Touches:**\\n   - Decorate the tree and car with additional details like flowers, clouds, or a sun.\\n   - Ensure everything is securely glued and stable.\\n\\n### Enjoy Your Creation!\\nOnce your project is complete, you can display it as a fun piece of art or use it as a playful toy. Let your imagination run wild and feel free to add any additional elements that enhance your whimsical scene!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke({\"question\" : \"Give me a recipe how to build ared car inside a tree with little hands that shakes a helicopter\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9UkCIqkpyZu"
   },
   "source": [
    "### Task 1: Creating An Evaluation Dataset\n",
    "\n",
    "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
    "\n",
    "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
    "\n",
    "```python\n",
    "questions = [\n",
    "    \"What optimizer is used in QLoRA?\",\n",
    "    \"What data type was created in the QLoRA paper?\",\n",
    "    \"What is a Retrieval Augmented Generation system?\",\n",
    "    \"Who authored the QLoRA paper?\",\n",
    "    \"What is the most popular deep learning framework?\",\n",
    "    \"What significant improvements does the LoRA system make?\"\n",
    "]\n",
    "\n",
    "answers = [\n",
    "    {\"must_mention\" : [\"paged\", \"optimizer\"]},\n",
    "    {\"must_mention\" : [\"NF4\", \"NormalFloat\"]},\n",
    "    {\"must_mention\" : [\"ground\", \"context\"]},\n",
    "    {\"must_mention\" : [\"Tim\", \"Dettmers\"]},\n",
    "    {\"must_mention\" : [\"PyTorch\", \"TensorFlow\"]},\n",
    "    {\"must_mention\" : [\"reduce\", \"parameters\"]},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfMXF2KAsQxs"
   },
   "source": [
    "####üèóÔ∏è Activity #3:\n",
    "\n",
    "Please create a dataset in the above format with at least 5 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CbagRuJop83E"
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    # general search / tavily\n",
    "    \"What are the best Python web frameworks right now?\", \n",
    "    \"What are the modern and productive SQL databases?\",\n",
    "    \"What companies desing the smart and fast LLM models?\",\n",
    "    # astrophysics from arxiv\n",
    "    \"Tell me more about constraining the effect of baryonic feedback on the matter power spectrum with fast radio bursts\",\n",
    "    \"Tell me more about testing the local void solution to the Hubble tension using baryon acoustic oscillation measurements over the last twenty years\",\n",
    "    # some strange query\n",
    "    \"Give me a recipe how to build ared car inside a tree with little hands that shakes a helicopter\"\n",
    "]\n",
    "\n",
    "answers = [\n",
    "    # should pass\n",
    "    {\"must_mention\" : [\"fastapi\", \"django\", \"flask\"]},\n",
    "    {\"must_mention\" : [\"postgresql\", \"mysql\", \"microsoft sql server\"]},\n",
    "    {\"must_mention\" : [\"openai\", \"anthropic\", \"google\", \"facebook\"]},\n",
    "    {\"must_mention\" : [\"frbs\", \"spectrum\", \"radio\", \"bursts\"]},\n",
    "    {\"must_mention\" : [\"hubble\", \"void\", \"copernican\"]},\n",
    "    # should fail\n",
    "    {\"must_mention\" : [\"sausage\", \"pepper\", \"abracadabra\"]},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7QVFuAmsh7L"
   },
   "source": [
    "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RLfrZrgSsn85"
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from uuid import uuid4\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"Retrieval Augmented Generation - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"My custom questions from Session 5\"\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\" : q} for q in questions],\n",
    "    outputs=answers,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciV73F9Q04w0"
   },
   "source": [
    "#### ‚ùì Question #3:\n",
    "\n",
    "How are the correct answers associated with the questions?\n",
    "\n",
    "> NOTE: Feel free to indicate if this is problematic or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lRTXUrTtP9Y"
   },
   "source": [
    "### Task 2: Adding Evaluators\n",
    "\n",
    "Now we can add a custom evaluator to see if our responses contain the expected information.\n",
    "\n",
    "We'll be using a fairly naive exact-match process to determine if our response contains specific strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QrAUXMFftlAY"
   },
   "outputs": [],
   "source": [
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "\n",
    "@run_evaluator\n",
    "def must_mention(run, example) -> EvaluationResult:\n",
    "    prediction = (run.outputs.get(\"output\") or \"\").lower()\n",
    "    required = example.outputs.get(\"must_mention\") or []\n",
    "    scores = [phrase.lower() in prediction for phrase in required]\n",
    "    percentage = 100 * sum(scores) / len(scores) if scores else 0\n",
    "    return EvaluationResult(key=\"must_mention\", score=percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNtHORUh0jZY"
   },
   "source": [
    "#### ‚ùì Question #4:\n",
    "\n",
    "What are some ways you could improve this metric as-is?\n",
    "\n",
    "> NOTE: Alternatively you can suggest where gaps exist in this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1RJr349zhv7"
   },
   "source": [
    "Task 3: Evaluating\n",
    "\n",
    "All that is left to do is evaluate our agent's response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "efcf57067cf743d8b4ce059a61cbe02e",
      "53e33aae3b97490c82aec7bbb0d6ebba",
      "ad84e0e971d3455db2efe7dd0d1f803e",
      "72adef9b70dd48198b7322b6c5b113cf",
      "8a61d045ffd44ac58f3f13eb10044836",
      "041e22a9b5514e36bd4d1dac01d5d398",
      "886d762f2a7c421382efb5502c6d42a1",
      "ab91fd625bbd43afbf8c6398193a88d0",
      "716557ad09874dcb989d75f7c74424cd",
      "77d4c0ebaae045b58efc4f789c9a2360",
      "0d622ccc56264fac8fd7508dbdbe6e29"
     ]
    },
    "id": "p5TeCUUkuGld",
    "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'RAG Pipeline - Evaluation - 837b-934de043' at:\n",
      "https://smith.langchain.com/o/de22f916-4054-4062-b948-9485f791faec/datasets/ccd63fa3-6b35-4c54-8d20-5599d8fe9b3d/compare?selectedSessions=e34f13b2-7fe2-4a71-b06f-af23059f5077\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231f818a25a74671839654d58f7a34fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_results = client.evaluate(\n",
    "    agent_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[must_mention],\n",
    "    experiment_prefix=f\"RAG Pipeline - Evaluation - {uuid4().hex[0:4]}\",\n",
    "    metadata={\"version\": \"1.0.0\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "eeEqU7s05Byu",
    "outputId": "78395075-a05d-4ebd-c798-ed968b935318",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ExperimentResults RAG Pipeline - Evaluation - 837b-934de043>"
      ],
      "text/plain": [
       "<ExperimentResults RAG Pipeline - Evaluation - 837b-934de043>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhTNe4kWrplB"
   },
   "source": [
    "## Part 2: LangGraph with Helpfulness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1wKRddbIY_S"
   },
   "source": [
    "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
    "\n",
    "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
    "\n",
    "We're going to make a few key adjustments to account for this:\n",
    "\n",
    "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
    "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npTYJ8ayR5B3"
   },
   "source": [
    "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-LQ84YhyJG0w"
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD7EV0HqSQcb"
   },
   "source": [
    "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oajBwLkFVi1N"
   },
   "source": [
    "####üèóÔ∏è Activity #5:\n",
    "\n",
    "Please write markdown for the following cells to explain what each is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6rN7feNVn9f"
   },
   "source": [
    "#### Explanation\n",
    "Here we initialize our graph and attach nodes to it. \n",
    "\n",
    "We will have 2 nodes, `agent` and `action`. The `agent` node under the hood will call `call_model` func, and `action` - `tool_node` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6r6XXA5FJbVf",
    "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1205a7610>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check = StateGraph(AgentState)\n",
    "\n",
    "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
    "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ22o2mWVrfp"
   },
   "source": [
    "#### Expanation\n",
    "\n",
    "Here we set start point of our graph. The initial request will be processed by this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNWHwWxuRiLY",
    "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1205a7610>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsXeF6xlaXOZ"
   },
   "source": [
    "#### Explanation\n",
    "\n",
    "`tool_call_or_helpful` is our router (conditional edge) that will make decision of where should our flow move after appending message to `State`\n",
    "\n",
    "We can see custom recursion depth limiter here:\n",
    "```python\n",
    "if len(state[\"messages\"]) > 10:\n",
    "    return \"END\"\n",
    "```\n",
    "\n",
    "`prompt_template` - nothing special, just prompt template with placeholders for rag. This prompt will be some kind of response formatter and quality improver. It will handle mechanism where model will improve self response.\n",
    "\n",
    "Then we see LCEL syntax for chaining components\n",
    "\n",
    "Then `invoking` LLM with user query\n",
    "\n",
    "And the last step is:\n",
    "```python\n",
    "# No need to continue if response is `extemely helpful`\n",
    "if \"Y\" in helpfulness_response:\n",
    "    return \"end\"\n",
    "else:\n",
    "    return \"continue\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "z_Sq3A9SaV1O"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def tool_call_or_helpful(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"action\"\n",
    "\n",
    "  initial_query = state[\"messages\"][0]\n",
    "  final_response = state[\"messages\"][-1]\n",
    "\n",
    "  if len(state[\"messages\"]) > 10:\n",
    "    return \"END\"\n",
    "\n",
    "  prompt_template = \"\"\"\\\n",
    "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
    "\n",
    "  Initial Query:\n",
    "  {initial_query}\n",
    "\n",
    "  Final Response:\n",
    "  {final_response}\"\"\"\n",
    "\n",
    "  prompt_template = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "  helpfulness_chain = prompt_template | helpfulness_check_model | StrOutputParser()\n",
    "\n",
    "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
    "\n",
    "  if \"Y\" in helpfulness_response:\n",
    "    return \"end\"\n",
    "  else:\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz1u9Vf4SHxJ"
   },
   "source": [
    "####üèóÔ∏è Activity #4:\n",
    "\n",
    "Please write what is happening in our `tool_call_or_helpful` function!\n",
    "\n",
    "So I already put some extended desctiption of what's going on in this function, but let's imagine the flow of our state\n",
    "\n",
    "1. Receive user query and send it to initial node `agent`\n",
    "2. `agent` will decide (using built-in mechanism of [Function Calling](https://platform.openai.com/docs/guides/function-calling)) which tool should we use here (reminder that we have `arxiv` & `tavily`) and put message into `State`\n",
    "3. Go to conditional edge\n",
    "4. `tool_call_or_helpful` will route app flow to `action` node since last message satisfies condition `if last_message.tool_calls`\n",
    "5. Selected tool will be triggered and put some context into State\n",
    "6. Response generation with context using LLM and put message to `State`\n",
    "7. Go to conditional edge\n",
    "8. `tool_call_or_helpful` will decide (using request to LLM) should we redo generation, or should we response to user\n",
    "    - If we SHOULD redo => get back to step 2\n",
    "    - If response is \"extremely helpful\" => return it to user (call `END`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BhnBW2YVsJO"
   },
   "source": [
    "#### Explanation\n",
    "\n",
    "Insert our router to graph and connect it to `agent`\n",
    "\n",
    "In dictionary we can see `output`: `destination`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVTKnWMbP_8T",
    "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1205a7610>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tool_call_or_helpful,\n",
    "    {\n",
    "        \"continue\" : \"agent\",\n",
    "        \"action\" : \"action\",\n",
    "        \"end\" : END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGDLEWOIVtK0"
   },
   "source": [
    "#### Expalantion\n",
    "\n",
    "Glue `action` - `agent` nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbDK2MbuREgU",
    "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1205a7610>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSI8AOaEVvT-"
   },
   "source": [
    "#### Explanation\n",
    "\n",
    "So on previous steps we made some kind of blueprint / skeleton of our Graph\n",
    "\n",
    "Now we'll initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "oQldl8ERQ8lf"
   },
   "outputs": [],
   "source": [
    "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFbCAIAAAA8wVBsAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU1f7APATEiAhjLCnqLgQECl1oGIF68QtbnH7qlVxVNzWUS20aq2t1VpnbVFx1KqggFo3igtwgQjK3gkQkpCd/P64vrz8NOyb3JvL8/2jH7335pwnlodz7r1n0NRqNQIAUJEB0QEAALQF0hsAyoL0BoCyIL0BoCxIbwAoC9IbAMpiEB0AaKyKUrmgQl7NV4qFSplURXQ4jWLENDCgI7Y5g23BsGtjTGfQiI6odaHBe2+SK86SvnspyHolsnYylklUbHO6maWhAZ3osBrHiGnA58qrq5RiobIoW+LckeXmxXbvaW5oDHmuC5De5MUtkD6I5rEtGJb2hu29TC3tDImOqKVy06uzXomKsyXtPNi9h1sRHQ71QXqT1P2L3PyM6r6jbFzdTYiOBX9PrpU/uVY+JMSho48p0bFQGaQ36SgV6lM/5PqPtWnvySY6Fi1SKdV3L3CNTQz6jLAmOhbKgvQmF6VC/fu699PWunJs9b4r3hjPblTIJKo+IyHDtQJejJGIXKo+vOH94t0dWkluI4Q+H2TJMKLFnygmOhBqgvQmkdM7c6atbUt0FLrWc4iVuY3h0+sVRAdCQZDeZHHnfFngJDtz69Y4EqHPCOvqKkXOm2qiA6EaSG9SKMgU84plbbpQ8CF5I3UfwLn7dxnRUVANpDcpPIjm9hvVqh8vWdgYOndkvU6sIjoQSoH0Jl52arVDO5Z9W6Zuqnv16pVUKm3eZ5VKZUpKCt4RfeA/xvbdc6GWCm+dIL2Jl5EssG1jrJu6oqOjZ8+eLRaLm/fx7du3h4eH4x3UB0ZMmlymKnwv0VL5rRCkN/HevxS5eeloBEuz221sfESzP95Ibl6mWa+gAcdNa3xOSyoFmRI3L7YRE//fszk5OREREa9evTI3N/f391+3bt2VK1e+//57hNCgQYMQQlu2bBk1alRKSsqRI0ewLrenp+eKFSu6du2KEKqsrBw0aNDy5cvT09Nv377t7u7u4uJy/fp1hFCPHj0QQpcvX3ZycsI35g7eprfPl+JbZmsG6U2wyjIZw0gr06e2b9+enZ29atUqkUj09OlTAwODfv36hYSEREZG7t2719TU1NXVFSFUWFgolUrnz59vYGBw7ty5ZcuWRUdHM5kfHgQcPXp04sSJBw8epNPpbDa7pKSkoKDg22+/RQjZ2NjgHrO5FSMXXo/hB9KbYCK+gm2ulf8LhYWF7u7u48aNQwiFhIQghKysrFxcXBBCXl5eHA4Hu2z48OFBQUHYnz08PBYtWpSSkuLn54cd6dat25IlS2rK5HA4PB7Px8dHGwEjhBANmZjRq6uUJuZ6MuWV3ODem2CiKgXbQivpHRQUlJiYuHPnzvLy8nouo9Fot27dmjdv3sCBA7du3YoQ4vF4NWd79eqljdjqYWLOEFUpdFwpVUF6E8zAgKalNUyWLFny9ddfX7t2bfTo0WfPnq3rsiNHjqxevdrDw2PPnj0rVqxACKlU/1sKhsViaSO2ehizDNT6sRSNHoD0JpixiYGwUiuNFY1GmzZt2qVLlwYMGLBz587a76trpglKpdLjx4+PHTt21apVPj4+3bp1a7BYbU8xrCyTQ88cL5DeBGNrrS+KvcRis9mLFi1CCL1586amNS4r+zD8UywWS6VS7FE59rT8o9b7IywWi8fj1XNBy1VXaethRCsE/44EM7c2rCyVa6PktWvXmpqa+vn53b9/HyGE5XD37t3pdPru3btHjx4tlUqDg4M7duwYFRVlbW0tFAoPHTpkYGCQmZlZV5m+vr6XL18ODw/38fExNzf/4osv8I1ZLFC27WpCg0YHJ3TsaQogCsfWMPpQYa9h+C88lp+ff//+/bi4OLFYHBoaGhAQgBAyNze3t7e/fv36vXv3qqqqRo4c6evrm5CQcPbs2ZycnNDQ0LZt2/7999/Tp0+Xy+V//vmnv7+/h4dHTZkdO3bk8/lxcXFJSUkcDgf3B2/pzwRymZray9ToEqzWQrwrR4u69jJ36wY/0yj6cGG3fpx2Hq135hy+oHNOvE4+ZqW5knrSu6SkZPLkyZ8eV6vVarXawEBDX3b58uXYG2+tmj9/vsaevL29fUlJyafHx48fv2zZsjqLUyO5RN2uK+Q2bqD1JoUT32aPX+piZqX5t61CoSgt1TBUU6VSqVQqBkPDpywsLNhsrXcHysrK5HINDw7kcrmhoYb1pNhstoWFRV2lJV7l0Rm0nkNggWTcQHqTQkay8P0L4dBZDkQHQhi5VH1s8/uFP3QgOhBKgWeUpNDpM1NEQ7wirTxC1wvJtyu+CLYjOgqqgfQmiyEzHE7vyiE6CmKkPaoSlCu69jIjOhCqgfQmCxoNTVnV5tQPuUQHomu56eIX9/lfToWmG39w700uokrF5UNFU9e0IToQHcl6LXp5nz96Ic7zxgEGWm9yYXMYX061OxCWqaWhbKSScrvy9cMqyG3tgdabjFRK9bXIEjqd1neUtZamixLr/QtRQjTXvacZvAbTKkhv8kp/KngQw/X0s7BzZVJjIJewUpH1WpSXXo0Q6jvKpvXstUQUSG+ye/NEkJEiyEmr9vbnIKRmmzNMOQy6oVamiOPOkEGrqlRUVymrBYqSHIlYpGrvxe7a09y+rY5Whm3lIL31g1qNclKr+TxZdZVSIlJKxDhPyRSJRFlZWV5eXvgWyzZjqNRqtjmdbc6wa2Ns4wxZrVOQ3gAhhNLS0sLDw//66y+iAwF4gifnAFAWpDcAlAXpDRC2MFubNq1lLE3rAekNEDZ1PC8vj+goAM4gvcEHpqamRIcAcAbpDT4QCmHvPqqB9AYIu/e2trYmOgqAM0hvgLB779p7DwFqgPQGCCFkYGDQtm1boqMAOIP0BghblTEnp5WuFUNhkN4AUBakN/jAzAyWOqMaSG/wgUAgIDoEgDNIb/BBPRsMAD0F6Q0+4PP5RIcAcAbpDQBlQXoDhL33dnKCFUupBtIbIOy9d2FhIdFRAJxBegNAWZDeAGFTSlxdXYmOAuAM0hsgbEpJbm6r296M8iC9AaAsSG+AYMYYVUF6AwQzxqgK0hsAyoL0BggWQqYqSG+AYCFkqoL0BoCyIL3BB7DOOfVAeoMPYJ1z6oH0BghmjFEVpDdAMGOMqiC9AaAsSG+AsPfelpaWREcBcAbpDRD23ruiooLoKADOIL0Bwh6twXxv6oH0Bgh7tAbzvakH0hsgmBBKVZDeAMGEUKqC9AYIa71tbW2JjgLgjKZWq4mOARBm6tSpIpGIRqNJpVKBQGBtbU2j0cRi8bVr14gODeAAWu9WbeTIkcXFxQUFBVwuVyqVFhYWFhQUmJubEx0XwAekd6s2ceLEj96H0Wi0wMBA4iICeIL0btWMjIzGjh1Lp9Nrjri6uk6cOJHQoABuIL1bu8mTJzs7O2N/xppuOzs7ooMC+ID0bu0MDQ0nTJiANeCurq6TJk0iOiKAG0hvgCZMmODs7Eyj0QYOHAhNN5UwiA4ANJZSoS4vlgnKFSotvMscGTj/3r17ft3GZj7Hf80WhqGBtaORmSX8sOkavPfWDym3K9OeCBBCNk5MiVhJdDhNwzZj5KQJbZyN/UfbWNobEh1OKwLprQeeXKuoLJP7jdTvbrOIr7geWThmoZO5NTTjOgL33mSXfLuyskyh77mNEGJbMMYucT31Q45cBi2KjkB6k5pSoX7zROA3kjqjwfuNsU+8yiM6itYC0pvUyotlRIeAMzMrw8J3YqKjaC0gvUlNUK6wcWISHQWezCwN1Sqig2g1IL1JTaVWS/XtOXn91GokrJQTHUVrAekNAGVBegNAWZDeAFAWpDcAlAXpDQBlQXoDQFmQ3gBQFqQ3AJQF6Q0AZUF6A0BZkN4AUBakN2im1LRXUqmU6ChAfSC9QXPExUcvWTpbIoGpnaQG6d1K8fmVVYKqZn8c2m29AKteUc3Llyl/RR55+SoFIeTexXPRohVdOnfFTsXHx5w8fby0tLh9uw40AwMHe8fN30QghIqKCw8c2PMs6ZGRkXHnTu5z5y527+KBENq0eVUbl7YMBiPmyj8KudzPz3/5snWmpqZx8dF7f/4eITR2/CCE0No1W4YNHUX09wYaQOtNNcXFhVKZdEbI/FkzFxQXF65bv0wikSCE7ifc/n7n1u7evps2fGdoZJSW9mpC8DSEEI/HDV02t0rAX7okbOGCZXK5fPmK+VlZ77DSzp6LLC4uDP9u79IlYbfv3Ig8eRQh1LtXv0kTQxBCEd/t/WXvkd69+hH9pYFm0HpTzaBBwwcPDsL+3KWLx9erFr18ldKzh9+lS+fatXNb9fVGhJC7u+fEycMTH9338Oj2V+QRS47Vj7t+YzAYCKHBg4JCZo6NufpP6JIwhJCLi+uG9dtpNFpXd8+7928+efpw0cLllpZWTk4uCKGuXb0sLDhEf2NQJ0hvqqHRaPfu3zp7LjInJ8vExAQhVFHOQwiVlpW4uHzYDNTGxpbJZAoEVQihR48SSstKgkb2rylBLpeXlZZgf2YaM2k0GvZne3vHV6+eE/GdQDNBelPNn38dOf7HweDxUxfMD+WVc7d9u06lViGEnJxc0tNTZTKZkZHR+/eZEomkY8cuCKHyCl6fPv0XzA+tXQibbfppyYYMQ5WKUitDUR6kN6XIZLJTp4+PCBq7dMkqhFDpfxthhNDUybO+Dlv0ddiiz317Xb9+1b2Lx9AhIxFCZmbmfH6lq2u7ZlQHe2CQHDxaoxSpTCqVSjv/91E5v6oSIaRSqRBCXl7dg8dPValUhYX5kyfP3PvTYexm29e316tXz9PfptUUIhY3/DabxWQhhLjcMm1+G9BS0HpTipmpmZtbxwv/RFlZWYuEwhN/HjIwMHj/PhMhdO78yeTkJ5MmzaDRaAwGIz8/t0OHTgihWTMXJCbeX71myaSJIZaWVo8fP1CqlDu+/bH+ijy9utPp9F8P7B4+dLRUJh09KlhXXxE0AbTeVPPNxnAWk/Xt9vVnzv311VcrZ4TMi4+PlsvlXTp7lFfwvgvftOO7jVu3rZ2/YOqen8IRQs5OLr/+cszT0/vkqWP7D/xYya8Y9OXwBmtxdnJZ9fXGvLycX/fvvn37uk6+GWgy2EKQ1DKfC988EQ6Y6IBLaUqlkk6nY7fovx/+5eLFs/GxD7Auus5Iq1UXf82e/52bLitttaBz3lpcu3blyLH9gQFDHB2dKyp49+7dbNfOTce5DXQM/u+2Fm3buXXz8rnxb2xVFd/a2qZf3wEh0+cRHRTQLkjv1qJL567fbAonOgqgU/BoDQDKgvQGgLIgvQGgLEhvACgLHq0BAuTk5FRXVwsEgpr/8ni8srKyLVu2EB0apUB6kx31hh1JJNJly9Zho2skEkl1dbVSqcSGV0F64ws65+T18OHDiIgINaJafhsbGykUioKCgrKyMoFAoFQqsWnqtra2RIdGNZDepFNSUpKQkIAQ4vF4CxcuNPjvagqUQaPRtmzZYm1t/dHxuLg4giKiLEhvcnn9+vWcOXNMTU0RQiNHjrSysiI6Iq3o1avX0qVLLSwsao4YGBhUVVUpFApC46IaSG9SuHnz5tq1axFCdnZ2V69e7d69O9ERad2oUaMmTZrEZDKxGemPHz9msVgKhWLYsGExMTFER0cRkN4EKy8vx9J77ty5CKGP7j+NjGlMNp246PCnUqttXZjYnxcuXDh48GA6nc5isRBChoaGTCYzMjISW0Q9OTn5+XNY2q1FIL0JEx8f36NHD7lcjhDasWNHly5dPr3G2tE4942QiOi0hVcopdX6oduyZUuvXr3Mzc1rjtjY2AQHB2MdmZ9//vny5cvEBEoJMN9b11JSUgoLC4OCghITE/38/Bq8/srRou4DbCxsDXUSnda9uFPOsWV49jFvxLUI691YWVmtW7fOxsZm+fLlhoYU+XfQDWi9derFixf79u3r1KkTQqgxuY0QCphge/tskUpJhd/Cr+5XCPnyNp5N+Aj2cDEiIsLZ2bmoqAghdPfuXS2GSC3QeutCXFzcr7/+GhMTIxQKsafiTSLiK09sz+o93NbU0tDCxkgfU51bIKnkykSV8uGzHQ4ePGhqahoSEtK8olavXm1pablhwwZsUWe8I6UUSG8tKiwsLC0t9fHxOX/+fEBAgI2NTWM+JZPJ8vPz8/LyMjMz3759m5WVxefz4+Pjn8RXFLyvViqQqBL/t0cqlVIslrDZbNxLRgjZuhgb0FG7ruwuPc2wI3v37p0/f76xsXHzOtsVFRWWlpanTp1KTU0NCwvjcGCnFM0gvbUlLi5u//79P/30U8eOHRv/qXnz5lVUVIjFYqFQWF1dja0l/vnnnx8+fFibwaK0tLTw8PC//vpLq7XUplAoUlNTX79+PXXq1GYXEhsby+Fw+vTp8/Dhwz59+uAaIBXAvTfObty4cejQIYRQ586do6Ojm5TbCKGkpKTc3NyysjKxWEyj0bChmrNnz9ZavB84OTktWrRI27XUxmAwvL29CwoKbt++3exChg8fjmV1dnZ2v379iouLcY1R70F640Yul5eUlFy/fj0oKAgh5ObWnMVA27ZtW/uvarXa1dW1Xz+tb8FpYWGhg1o+FRYW5uXlhRC6ePFiS8qZOnXqv//+y2AwZDJZWFjYmzdv8ItRj0F64+DcuXN+fn5KpdLGxuaHH35wcXFpdlEXL140Njau+auVldW8ebpY8LCwsPDgwYM6qOhT2COJnJycffv2taQcJpNpY2NjZGQ0YsSI6OhorEz8wtRLkN7Nl5eXl56ejv1g3b9/n8lkYquIt8SmTZuGDh1qYGCANd0dO3Zs5PuzFuLz+dg8FqIsX7582LBhCKGWhxEYGLh69WrsS/n7+z969AinGPUPpHczJSQkhIaGYsOtRo0a1fIFwzMzMwcPHuzv77958+bHjx+r1WorK6s5c+bgFG8DdH/v/SlsOEBRUdHu3btxKdDb2/vGjRvYw/kLFy68ffsWl2L1iRo0xYMHD7755hu1Wp2Xl4djsadOnZo0aRKPx6s5MmTIkCVLluBYhR5JS0tTq9VPnz7Fsczk5OQpU6bw+fzq6mociyU5SO/GKisrU6vV69evf/PmDb4lr1u3bteuXfiW2VQZGRkrVqwgNoaPnDt3btWqVfiWKZPJiouLJ06cmJSUhG/J5ATp3bAXL14MHz48MzMT95KfP3/et2/f+/fv415yU6WmpoaEhBAdxcdu3bqlUCgEAgG+xWZmZl68eFGtVicmJuJbMtlAetfn3r17arX69u3bxcXFuBceFRU1e/ZssViMe8nNIJVKtfEdcZGXlxceHq6Nkm/duvX5558XFRVpo3AygEdrmnG53F69emHjxgYMGGBvb49v+YsXL5bJZMePH8fWMyCckZER7t8RLy4uLp06ddq/fz/uJQcEBDx58gR73/HLL79UVlbiXgXBiP79Qi5isXj//v1qtZrL5SoUCm1UkZyc3KtXL7J1C/Pz87EvTlp8Pl+tVsfExGip/HPnzk2bNg3ryGipCt2D1vsDbL3OGTNmYO+6rK2tW/4S+1OnTp3at29fQkJC7969cS+8Jaqqqh4+fEh0FPXB/r9kZ2dHRUVpo/wJEyacPHkSIZSamrp161ZqtOQwpQTJ5fJff/21f//+PXr00GpFS5cu7dGjhw4GkDeDRCIpKipq37490YE07OXLl926dSstLbWzs9NSFTExMfn5+YsWLeLz+bXXe9Q7rTq9FQoFg8HYt2+fpaVls6cfN0ZaWtr8+fN3794Ns5rwsnbt2tGjR2t7nPzx48dzc3PXr1+vrxPLib47IIZKpdq3b19ERIQO6rpw4cL06dNJ8oS8Lu/evVu/fj3RUTTNvn37dFDLpUuXnjx5olarcX8/pwOt9N47PT3d1NR03bp12q5o3bp1FRUVkZGRJHlCXhepVJqXl0d0FE2zdOlShJCWbsVrjB49Grtrmzp1qi7nw+OD6N8vOnX16tXevXvrpq7S0tKgoKBr167pproWEolEqampREfRHDk5OV9++aVKpdJBXdhgmIyMDB3UhYvWkt7v37/HhnbLZDIdVPfvv/8OHTqUwuMlSAVb3wYbNawDaWlpgYGBOTk5uqmuJajfOS8rKwsODuZyuVj/Sgcr6R47diw2NjYuLs7BwUHbdeElPz9/7969REfRTBwOh8lkvn79OjY2VgfVubu7//PPP9hP1KtXr3RQY7NROb2xCYAFBQU//vhjz549dVPp4sWLzczMdu3apZvq8CIQCJ49e0Z0FC0yYMCAhIQEmUymg7osLCx8fX0RQufPnyf1psVEdx+05bffflu0aJEuaywoKAgICCDbcLRG0t97749IJBLsQbfOPHz4sGYSK9lQsPV++vQpQsjLy+u3337TWaU3b95cuHDhpUuXyDYcrZFMTEy6du1KdBQ4MDY2ZjKZ27Zt01mN2HI6RkZGAQEBZFvLkVLpLRQKAwICsJWM/P39dVbviRMnYmNjo6Oja++VpV+ys7O3b99OdBT48PLy+uyzz3RcqZubW0xMTGlpKUKIPElOkVFr2dnZdnZ2AoHAxMTEzMxMl1WvXbu2e/fu06ZN02Wl9ZNIJNjOhI3H4/EePHgwatSoptbFZrOx36dkU1lZyeVym7oQNS4mTpw4d+7c4cOH677qj1AhvaOjo0+cOHHmzBltTAKp36RJkxYsWDBo0CAd11s/gUAgFoub9BG1Wq1UKpuxYpyVlVXL15nTkhs3bly/fv2HH37QfdVXr14NCgrKy8tr06aN7muvod/p/ebNG3d39zt37gwYMEDHVefk5EyYMCEqKqpDhw46rrpBzUjvZiNzemOLpQqFQmdnZ0JqP3r0aEVFRVhYGCG16/e99+rVq7G3jrrP7YSEhJUrVz569IiEud08KpUKW7uCYrD5XkTtajBv3jwXFxc+ny8SiQgJQC/Tu7CwUCwWDx8+fMKECbqv/cyZM//++++FCxfIec/ZPCqVSjdvjHXP2dn59u3bR44cIaT2KVOmmJubFxYW/vzzz7qvXc9+QFUq1YoVK8rLy1ks1sCBA3UfwN69e3NycjZv3qz7qrWKTqfXvz1oYWFhUFBQS/YDI9CiRYvGjBlTVVVFSO00Gq1Tp06Wlpa6GVRXm56l9+XLl4ODg7FdqXRv7dq11tbWa9asIaR2raLRaDoYrksgW1vb7OxsPp9PVAAzZ87s378/QujKlSs6q1Rv0hsbET127Fjs30j3Zs6cOXjw4BkzZhBSu7apVCqi7g91xtvbe8yYMUKhkKgATE1NEUIpKSkxMTG6qZG8zzxr27lzp4eHB4EBzJo1a+3atZ6engTG0EJXrly5cOECj8ezt7cPCAgYP368sbHxu3fvwsLCtm3bduzYsaysLHt7+7lz59bsalZZWXno0KHExERjY2Nvb2+ivwEOrl27lpqa6uPjQ2AMGzduxB4J62ClJ7K33tgI03nz5o0cOZKQAKRSad++fX/88Ue9zu2TJ08eO3bsiy++WL58ub+///nz52u245RKpREREePGjQsPD7ezs9u5cyfWg5XJZBs3bkxMTBw3btycOXPIMxKrJYyMjDp37szj8YgNA7u7XLdu3fPnz7VaEanT++LFi9j3t7a2JiSAsrKywMDAW7duYZvU6ikej3fmzJmVK1fOmjUrMDBwxowZ8+bNu3nzpkAgwC5YtGjRgAEDPD09Z8+eLZFIsLYlJiYmKyvrm2++mTFjxpAhQwh8eYsvExOT/fv3X7p0iehA0G+//Xb9+nWtVkH2zrludrfWKCsr66uvvnrw4AFRAeAlOTlZoVDs2rWrZpoqNpapphFjMpkqlUosFmNrj2LHHzx40K5du5rB27ofEag9mzdvjoqKqq6uNjExITYS7JfmhQsXxo8fr43ySZrehw4dWrBgwdixY4kKoLq6eu3atXFxcUQFgKPy8nKE0NatWz/qgzg6OtZscK9SqRQKBbYeqEqlwnoulBm086kpU6YQHcL/uLq67tixY9OmTbiXTMb03rFjx9SpUwkMIC0t7bvvvjt79iyBMeCoZo5NPeOf6XQ6i8XC9nLAWFhYUGMp/7ocP36cw+GMGzeO6EBQjx49tLTQMhnvvWfNmkVgu4HldmRkJFEB4K579+40Gu3y5cs1Rz4dkU6j0T76CevQoUNGRkZ+fr6uwtS1OXPmxMfHEzXW5SPYi4nw8HB8iyVXeu/evTsnJ4fASTbUy22EkJOT0+jRox89erR169b4+PioqKj58+dnZmbWvga79659ZNKkSQYGBmvWrDl79uyNGzcOHDig88C17uDBg6Saoj9lypT169fjWCCJOucRERGDBw9u27YtUQFQMrcxCxYssLW1jY6OTkpKsrKy6tu370cvI1QqlVQqNTY2rjni6Oj47bffHj169OTJkzY2Nn379k1KSiIidu26fv26h4cHUVPKPuLm5hYREYFjgfo9IRRHmZmZBw4c2LNnD9GB4KAZE0KxKSXN2GuB5BNCG5SRkfHNN99oey+EJsnJyTl37hwubyJJkd4pKSnv3r0LDg4mKoDCwsKFCxdGR0cTFQC+YL53k6Snp1taWmpvQ8JmSEpKSkhICA0NbWE5xKd3aWnpqlWrCNzepaqqasyYMbdu3SIqANw1r/WWy+W1O+eNRIH0pjDiH63Z2dkRmNtqtXrgwIFUyu3m+fTRWquydetWEm5vHhkZiQ3KbjaC0zszMxPbbIAoCxcuvHv3LoEBkISBgUEzmm7KmDhx4rlz54iO4mMhISGnTp1qyWh/IjvnYrF48ODB9+/fJyqACRMm7N69u127dkQFoCVw7w0wRLbeWVlZBD6xXLp0aVhYGPVyu3nUajVVF2NqpPLy8tzcXKKj0CA1NfXff/9t3meJf7RGiO3bt3fr1o3AMe1apVKpsHHjjZeZmbl///6ffvqpqXVRpulWq9U9e/Zs4b2ulixbtmzy5Mn9+vVr6gfpW7du1U5IDTh37lxaWhrTrpVtAAAdu0lEQVQhizQcPnyYxWKFhITovmrdoNFoBk2kUCiEQuHnn3/e1A8S/V1xQ6PRrK2tZTIZCfd1HTZsmIGBQTMG2BHWegcFBR0/ftze3l7H9cbGxiYkJOzYsUPH9QLQElVVVQqFwsrKqkmfIua3r0qlunz5su5z+82bNydPnoTc/lR5eTk1Zr+20OnTp8n5DMLc3Hzu3Ll5eXlN+hQx6W1gYKD7ezaJRDJ//nxKDilvuZKSkpMnTxIdBfHevn1L2l9zP//8c3JycpM+Qkx6L1y4MCUlRceVTpgw4fz58zquVF/Y2tqSYeYz4ebNm8fhcIiOQrO2bduOHj26SR8h5t67f//+8fHxulwKZ8OGDaNGjerTp4/OagQAd1lZWfHx8YsWLWrk9QS03kqlMjo6Wpe5ffDgQTc3N8jtehQVFRG1TQ/ZnDp1Kjs7m+goNGvfvv3Tp08b3/MlIL3pdLou+z+3b9/OyMiYP3++zmrUR5WVlXfu3CE6ClKorq4m7e03QujXX391cXFp5MUEpPfTp09Xrlypm7qKi4t37dr1448/6qY6/WVnZzdp0iSioyCFcePGkXlNeyaTaWFh0ch7agLSu3kv6Jtn1qxZJ06c0E1des3a2nrUqFFER0EK1tbWRG101UinTp2q2YWifgSkt6+v77Zt23RQUVhY2Pr16/V6BwKd4fF4lFnNouV+//13Mq8hGRwc/Pr168ZcSZ1BhR/5448/2rZtGxAQQHQg+qG0tJQyCz+3XEVFRWJiItFR1MnU1PT3339vzJUEpHdlZeWECRO0WsXz58/z8vJavpZN62FjY9PUd6oUNnPmTDLffmObTLx586bBy4h57+3v73/9+nUWi6Wl8nv06EHOqT8A4EIqlQYGBja4QxYxnfP79+9rL7f/85//HDp0SEuFU1VxcfGxY8eIjoIsFArFsmXLiI6iPsbGxosXL3737l39lxGT3iUlJVraRf3kyZNffvmlr6+vNgqnsIqKClhwrgaDwcjNzSXz0zVsqaYGN/MhZi5+dHR0ZGSkkZGRUChks9l4bYP67NmzO3fuQNPdDNbW1sOHDyc6ChLZv3+/hYUF0VHUp7Ky8t69e/W/ztTpvffQoUN5PJ5Kpaq9DICHh8eff/6JS/k9e/Z89OgRldYYAKAegwYNOnfunKWlZV0X6DQTli1bZmNjUzv91Gp17969cSl848aNBw4cgNxuHqwpIDoKEomLi8Or1dGeTZs28fn8ei7QaTKMGDHC39+/dgba2to2YwWpT/3xxx8ODg49e/ZseVGtU1FREdzU1MZkMp8/f050FA0ICAiofy1QXbd1mzZtqv08wMLCwsfHp4VlYktJwlvuloAx5x/p2bPnrFmziI6iAXl5efUPRiKgK7tx40ZsG1C1Wt3y3EYILV68+LfffsMjtNYLxpx/hM1mY3tukxmHw6l/Y2YC0tvLy2v8+PGmpqYcDueLL75oYWmrV6/evHmzqakpTtG1UoWFhQcPHiQ6CnLZsGED0SE0wMzMbN26dSKRqK4LGvFiTI3kMnW1QIFjWCOHTnrxLDMnJ6dTu+58rrzZ5cTFxdly2n7u3b8RhdAsbCiyIrc28Pn8hISExi8D0ho8fvy4oqKinufSZDBs2LB6zjbwYux1YtWLe3w+V8ZikzA31CqVupGPyq2cjPLTqzv6mPmPsWaZ0rUfm36YPn16amoq9m+oVqtpNBr2h6SkJKJDI96DBw+8vb1J3jGMi4vjcDh+fn4az9aXtE+uVXCLZAGTHE05JMztJlPK1eUlssiI3KlhrqaWkOEIIfTVV19t2bIFe7lSk9sNjoVqJfr27Ut0CA2rrKx8+fJlXeldZ9P3KLacz1P4j7WnRm4jhOiGNFsX4ylr2p/8PlsmadoePVTl7+/foUOH2j04JpNJ4f1bmuTIkSOvXr0iOooGfPnll4GBgXWd1ZzeFaVybpGsd5CtNgMjTOAUpweXeURHQRazZs2qPfqyXbt2Y8aMITQissjOzm7qtgG6Z2tr26NHj7rOak5vboEUUXdnQQtbo/evtDKhRR/169evS5cuWANuYmIyefJkoiMii9DQUPKvrisSierZdUdzegsqFTbOTG1GRSQTM7qlvbG0GvrnH4SEhGBLVjVjoXwKs7e3J+2WBjXYbPbly5eVSqXGs5rTWyFVUfvutKxAgmhEB0EaWAPOYrFg4FptUVFRZ86cITqKhu3atUsu1/ximCKPzVoViUhZkCmpLJMLKhUqJRJV4TAkwa9dqKNBLir2jD5c3MKi6HQa3ZBmxmGYWtKtHYycO2pr3Q5tE4lEUqmU6CgaNmDAgLpOQXrrDZUSPb9Xmf5UWMmVcRzM1EhtaMwwYhmq6IYtL9yEw+rKsdPcw2tqnDSaRKLi5yjkb+U0JOEXF7b1YLv3MHPrxsajeN0JDg6uq9NLKocPHx48eLDGuSWQ3npArUaJseVJN8odOlmaO1s5eBoTHVETOHSxriqtfp5Q/SCG13+sTduuutt8qoXIf+ONSUtL69y5M6S3Xip4J7l+ssTUhu05uD3RsTSHAZ3GcWQjxGZZye5dLk9/Khwyw47ooBolJiYmLy/vq6++IjqQBsydO9fKykrjKVj8gNRS7vBvRJW5+jrbtCf1yOfGYJoZuXg7KBimhzdmiYV60OmVSCT1L5ZAEl5eXk5OThpPQXqT16sHwjdJkra+TgZ06jzlN+EYt+/lfGJ7jlhE9lczgwYNmj17NtFRNCwmJub+/fsaT0F6k1RibMXLRJGDOwV3UGIY0d0D2p74NltC7qEHHA7HwcGB6Cgalp2dnZGRofEUpDcZvX8pynhe7diVgrldo4OfS2R4DtFR1OfWrVuRkZFER9GwESNG1PVuDNKbdER85ZN/+W2660G70RKGTLqDu+2N02VEB1Kn8vLy3NxcoqNoWPv27d3c3DSegvQmnXuXuExzPXtF3Dym1qzCLGlRloToQDQbMWIEyfcqwdy9ezcmJkbjKUhvcqkokRW+l1g4knoJARzZtLe6e4FLdBSaMZlMkq/lgCkoKKhrO0Ei07u4uKiouLD2kauxl8aOH1RS0tJxkfor+Tbf1s2a6Cg04PLywr7pnfziGr7FmnCM6UyjvLdifIvFxZUrV3755Reio2hY//7961oGk7D0LijMnxYyOj09tfZBIyNjNtu0NW9FkPaYb2qjr4O0m8fA0DDzORnn50okEi3thIcvFxeXLl26aDxFWCIpFYpPl3kb9OWwk39dtLXVj1FNuMtJq7awZdGo85K7Ucxs2e9f1rnWJ4H05d47MTHxwoULGk/hNig1Nu7yxYtn32dlslgmvXr2WbokjMP5MNCqpKT4yLH9T548rK4WdejQedLEEHd3z1lzJiCEtn27bhtCQ4eOXLdm6/c7t8bHxyCErscnMhgMhNC1a1dOnj5eWJhvbW0zImjc9GlzDAwMMjLTQ5fN/T78l0NH9r1799be3nHhf5b161fnpBk9UvBObGqrrZu9B4//vpNwil9VamXp9Jn3kIB+IYaGxgWF6b8e+c+8GT9dvXagsPitJcdxxJClXl0/rE4tFFVcuvrT6zd3DRnGHdp/rqXADJl0cxsmt1Bm42SkpSqah8nUjyUPCgoK0tPTNZ7CLb1TU1+6urYbPDiooqL8wj9RompRxHd7EUI8HndJ6GylUjll8kxLjtWLl8lcbqm11YCNG3Z8F75pzuxFn/n0sLS0QgiNHzdFpVJdv34VKzA+Pub7nVu//HLYvLmLU1NfHjv+G0JoRsg8bO/ybdvXhS5d7ejgdPyPgzvCN0adirGw0I8JAPUozpYaWmhlusi1m4fvJJzy7zPZ3rZ9KTfn9r1ILjdv6oStCCG5XBp5ZuPYEassOY7xNw+dOvfNxlWX2GyOXCH7/Y9QHi/vi37TrSwdHzz6WxuBYaRilaBcTrb0vnLlyrt378jfgPv5+Xl6emo8hVt6f71yA+2/3UoGgxF58phUKjU2Nv7zr8OVlRXHjpxxdW2HEBo6dCR2TedO7gghV9d23br51Bxp1/bD6zu1Wn3k2P5u3Xw2bdiBEPqi/0CBoCrqzIng8VOxC0KXrh4YOAQhNH/+0oWLQp6/SPqi/0C8vgtRqgUKGzv8l3DlV5X9e/eP6RO2e3t9+CeyMLP5O/qHMUFfY38dO2KVT7fBCKGgwYv3/jbrXXayt2dgQuK5ouKMBbP2de7YCyHUrk23nb9oa50muiEdl1nr+NKXe29nZ+e6TuGW3nK5/MI/UddvXC0tLTY2ZqpUqsrKCnt7h0ePE3w/64nlduPl5+dyuWWTJ82oOdKzZ5+rsZfyC3KxXyIs5ofnT/b2jgghLpe8oyMaTy5VM4zxn8OX8e6xUqk4eX7zyfOb/3tMjRDiC0qxvxgZfvjHtOQ4IoSqBGUIoVdpdxztO2K5jRAyMNDi0tEMY8PqKtINUB0xYsTQoUOJjqJhT548KSoq0riKFj4/TGq1esPGFelvU2fNXODh4X3v3s2oM3+q1CqEUEVF+ee+Td7iVygSIoQ4nP9NczMzM0cIcctKbe3sa19pyDBECKlUejADqUFKhQppYbv1KgEXITQvZA/H4v89s7S2cikueVf7CIP+v3/MSn6xs6Pm57G4U6tUiEa61yVXrlxJT08n/1ZEubm56enpWkzv58+TniU93rhhx6AvhyGECvL/N5TP1NSsvKLJqw7b2dojhPj8ypojFRXlNUlOVSwzhlyqZBjj3E6yWB/+0exsm9CHMmVbCkUV+EZSF6VcybYg1423HunZs6d2X4zxqyprbqdr/qpSqRBCvp/1TEp6XHv4ikKhQAgZGzMRQrw6OtXW1jYO9o6PHyfUHLlz5waTyezYUUftCSHYZnSFFP9b0E5uPWg02v1H/9spVipreBiJs2OXvILU0jJdzPpQyhVsc9KtLBIcHEz+phsh5Orq6uXlpfEUPv+mHl27GRkZHT7y64gR496/zzh1+jhCKOt9prOTy4yQ+Q8e3l0aOmf8uClWVtZPnyayWCZhqzbZ2dk7OTqfPR/JZLGqqvjjx00xNv5/D41nz1r4/c6tu3Zv79mzT1LS4/sJt2fNXMBiUXnIh0N7ZnEB/regNtZt/P0m33sYdSxylWfXAQIBN+HR+Xkz9rg4udfzqcD+M5+mXD1wbNEXfaaYm9kkvYjHPbAahkY0C2scVoxrnZKSkoqLi4OCgj49hU/rbWtrt2njdxmZb7ZuW/Ps2aM9P/7u5+d/4Z8o7Nn4vp+PdezQOfLk0d9++6m4pMjHpwe2o9WmTeEmJuxf9++Oi4/G+t61DR06csXydc9fJH0XvunJk4cL/hM6a+Z/cImWtNp0YgnKBNooefTwFaOGLSsqeXch+odHzy55eQRYmDcwdsjG2uU/M3/mmNvF3zx8/fYxJ/tO2ggMISQVySUCuaU96dL777//Dg8PJzqKhmVlZaWkpGg8pXmH0Mdx5VIJ8gnUvIATBZz+4f2sb9oZs0j3OOfgmned+7saMEgXmPZwc/j29qr+40g3uf3vv//Wi0dr7969q6io0LgVEelueFo5jz6cSp7Y3L7OCaHx/x66l6hhbX0XR/f8Is3ThkL/c8TeDrdlGK9eP/DgsYYhLiymmViiueux8qs/ra3qfDerlis6+VjUdZZAwcHBRIfQKPXs6ArpTS6fD+Sc/CG3nvTu32dKT9+Rnx6n0ercqr3BfniTDOg33a/H2E+Pq9WortHy9QQgKKumG8gd2uvT0s5k8/Lly7KysoEDNQzrgvQmF7YFvaOPaXlelVUbza8ATUzMTUyIfDvINrFgm+DW2Ja9Lx+z0BGv0vClL53zN2/evHv3TmN6t6J7PH0xYLytXFhNdBS6IOSKOvmYWjvCG+8W8fT0rGutNWi9SYfOQIETbWJPFLT9vM77VQqQCGRVhfyRa9sQHUid9OXe28PDo65T0HqTkV0b4x6DOPkvSogORFtUKvQusWAaiXMbISQWiwUCrbynxNerV68ePHig8RSkN0l5+pkHjrcqeEnBDBdXydL+zVqyuyPRgTTg6tWr+/btIzqKhj1//jwxMVHjKUhv8nLuxOwz3CLzQZ5MTLrJks0mKBVVZHOX7OlI/h89Q0NDvVjRwdPT08/PT+MpuPcmNbdubBtn49jjxWoDho2bFcNIi7MytU1QVs3NKu/kYzpqFqn75DU0zsEiIR8fn7pOQXqTnbkVY/Iql7THVfcvFpjbmzDNWWa2Jnq065hUJK8qrUZKuRFDOWaho5WD3jwnl8lkCoXCxITsOxa/ePFCqVR+9tlnn56C9NYPXXuZd+1lnpEkfJssfHOnzNqZrZCp6EYMQ5aRSkmuhRBoNJpKoVTKFQqZks6gycXyDt6mHbtbOLTTg45ubXFxccnJyVu2bCE6kAYkJiaq1WpIb73Xyde0k68pQqgkRyriK0RVCrlcLRXhvwJESxgYqOmGdLaFEducYW5jxLHR158xExOTj2YxkpO3tze29Oin9PWfvpWzb2uMkB785Om1QYMGDRo0iOgoGlbXc7U6n5wbsQyMmKR/stkCdm2YenPzCgiiUqmwpUdI7vHjx6mpqRpPac5hc0vDklwy7guDC2GlorJMZkS+2aCAVO7evbtu3Tqio2jYzZs3X79+rfGU5s65nasx7ZGWgyJORbG0g7cebA0HiGVhYWFjQ7pZ6J/y8/Ozt7fXeKrOWYTP7/Lz3ooHTKTaLtNKOToZkbnkR7IPmQKg5ersoHb/wqLTZ6Y3IgtL8yQyCblevTRPFU+el159MiJzQbjmvc4BqE0kEmVkZBAdRcNu3Ljx/v17jafqe3Le5XNTFtsg5U55cbZEqSDX25emcmjHElbK3bxMod0GjZSfn79t27ZTp04RHUgDLl++PHnyZDc3DY1WAy/GXN1NXN1NEEJKuX6nt5pGq+PVIACaWVhYtG+P2yJW2jNy5MiOHTU3WnXeewMA9B28HAJAM6VSWdfGuqRy9OhRLper8RSkNwCa0Wi0kJAQoqNo2N9//61Uat5jD9IbAM0MDAxcXFykUinRgTRg5cqV1tbWGk/BvTcAlAWtNwB1ksvlJG//xGJxREREXWchvQGo0+LFi5OTk4mOoj5cLvfRozoHkEN6A1AnFxcXkUhEdBT1MTMzW7lyZV1n4d4bAMqC1huAOgmFQpK33q9fv75y5UpdZyG9AahTXFwcyZc6f/bsWWZmZl1nYRw2AHVycnJ680bztsok4e3tzWKx6joL994AUBZ0zgGok1KprGs4N0lERkbm5eXVdRbSG4A60en0oKCgukZ0k8GZM2fo9Dr3roH0BqA+3t7epaWlREdRpyVLljg6OtZ1Fu69AaAsaL0BqI9QKJRIJERHodn79+8PHDhQzwWQ3gDU559//jl48CDRUWj24sULHo9XzwWQ3gDUp3PnzuXl5URHoZmvr+/cuXPruQDuvQGgLGi9AWhA/R1gAkVERNT/Wh7SG4AGrFixoq49+ggklUqjo6Pr3yYJxpwDPSOTyXRc4+jRoysrK7Vdr5GRUZOul8lkDU53gXtvoGd4PB6Zh5E1m52dHe5lQuccgIapVKTbZu/UqVMPHz6s/xpIbwAaRsJ3Y5cuXbK1ta3/GuicAz1DSOdcKBQymUyGNvepa1LnXKVSvXr1ytvbu/7LIL2BnoF778aDzjkA/09JSUlxcXHtI3v27Fm+fLlCoSAuqI/98ccfly5davAySG8A/qeoqGju3LkZGRm1D5qYmLBYrMrKSuLi+lh8fHzXrl0bvAzeewPwPwqF4tPb1UWLFiGEJBKJUqmsZ+0EXYqMjGxMJHDvDfSMxnvv+Pj4y5cv5+fns9ns3r17z5w509LSsry8/PDhw0+fPlUqlR4eHvPmzWvfvj1C6OLFi3fu3Bk3btyJEycqKio6dOiwbNmyNm3aFBcX156hMWjQoK+//nr27NmlpaUeHh67d+9GCE2cOHHJkiUPHz58/Pgxm80OCgqaNm0aQig5OXnjxo179uxxd3fHPj5u3LjRo0fPmTMHIVRcXHz48OHk5GRjY+MOHTrMnDmzc+fOH32Fxt97q9VqtVptYNBw1xs650DvRUZG/vzzzy4uLqGhoePHjy8uLjY0NJRIJOvXr09JSZk7d+7SpUt5PN6GDRuEQiH2kfT09AsXLixbtmzTpk1cLnfPnj0IISsrqzVr1iCEZsyYsWvXrsmTJyOEli1b1qFDByypsN1C9+zZ4+bmtnPnzoEDB0ZGRj5+/Lj+8MrLy8PCwgQCwcKFC+fMmaNQKNasWZOdnd3s77t69eo7d+405kronAP9xuVyz5w5M3DgwLCwMOzIhAkTEEKxsbF5eXnh4eE+Pj4IIU9Pz7lz516+fBlrbBFCW7ZssbS0xMacHj58uKqqytzcHMtkFxcXT09P7DJfX98LFy5IJBIajSYWixFCQ4YMwTLfzc0tPj4+KSmpV69e9UR4+vRpDocTHh6OvVcbOHDg/Pnz4+PjFy5c2Lyv/PTpU6wr0SBIb6DfkpOTlUrliBEjPjr+4sULNpuN5TZCyN7evk2bNm/fvq25gMlkYn/AesU8Hs/c3Lz+uthsdu0P0ul0a2vrBueTPX36tKysLDg4uOaIXC4vKytryrf8f27fvt3IKyG9gX6rqKhACH06caq6utrCwqL2ETMzM42Dz7BGtTHDTg0NDT/9bIMv4SsqKnr16oXdhNfAflM0Q2lpqampqYmJSWMuhvQG+s3U1BRLoY9GaFpbW3+0wcin1zSPxqfRNBqtngirqqratGnT8qqFQuHEiRMbeeMNj9aA3sMGZsbHx9ccwcafdO3aVSAQ1GR4VlZWYWFhzR11XYyNjRtcv0Hj+BYOh1P7g+Xl5TWX+fj4pKam1n6Xjt3DN8PTp09DQ0Mbfz203kC/ubi4DBs2LDY2ViAQ+Pr6VlVVxcbGRkREBAYGnj17NiIiYurUqTQaLSoqysLC4tNb9I/Y2to6ODj8888/TCZTIBCMHj0aS/jaNL6RcnFxsbOzi4qK4nA4YrH4xIkTNb396dOnP3nyZNOmTePGjeNwOM+ePVMqlZs3b27Glw0ICGjS9dB6A723dOnSWbNmZWRkHDhwIDY21tfXl8FgMBiMHTt2dOrU6fDhw7///ruLi8vOnTuxR+X1oNFoa9euNTEx+f3332/cuKFxpJrG8SQMBmPDhg0MBmPTpk3Hjh2bNm1azfIMjo6Ou3fv7tq169mzZw8dOsTn8wMDA5vxNcvKyuLi4pr0ERjWAvQM4VNKlEqlSCRq8DF7UzU4rGX9+vWBgYFDhgxpfJnQOQegaeh0Oo1GUygUWp0f+hGZTBYUFNS/f/8mfQpab6BnCG+9tQQmhAJAFjr+FTN9+vRmfArSG4DmUCqVAoFAN3UdPXq0X79+zfggdM6BniFP51wkErFYrMbM3GqMejrnYrGYxWI1o0xIb6BnSLtfZwsZGxtrHPpWVVWlVqs/GmDbSJDeADTfX3/9NXToUG08FcMolco+ffo0OOe0LnDvDUDzde7ceevWrdor/+bNm3v37m32x6H1BqBFioqKOBxO8+6NtQ1abwBaxMbGRkubHERGRqakpLSkBEhvAFrE0NDw9OnTp0+fxrfYlJSUBw8e1CxH0TzQOQcAB3v37g0NDSXJOqo1IL0BIJ2KigqFQtHyxSegcw4APv7444+WrH9ao7KycsKECbgsLAPpDQA+RowYgW140EK3bt06cuQIHhFB5xwA/GA7mTR7mUTcQesNAG6YTOb79+9rNktoKoVCUXublJaD9AYAT46Ojtg+Cs2wf//+lStX4hgMdM4BwBmXyxWJRG3btiU6EGi9AcCbjY1NU3O7qqrq4MGDuEcC6Q2AVvTp06cxO59g5s2b16Q1EhsJOucAaEVGRkZcXFxjdh0oKytjMBgNLtLcDJDeABBJIBCUl5dr6UYdOucAaNGuXbsyMzPrOisUCkeNGqW9h3CQ3gBo0erVq2NiYuo6y+Vya++OhjvonANAjPz8fENDQ3t7e+1VAa03AFp39erVixcv1j5y+/btvXv3ajW3Ib0B0IWgoKCXL18+f/4c+6tcLler1bt379Z2vdA5B0DX8F0gvR6whSAAOlJcXHzz5s3c3NyOHTs2e1x6k0DnHAAdcXBwYLPZbDZbN7kNnXMAqAxabwAoC9IbAMqC9AaAsiC9AaAsSG8AKAvSGwDKgvQGgLL+D188qeS5Plk/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        agent_with_helpfulness_check.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F67FGCMRVwGz"
   },
   "source": [
    "#### Explanation\n",
    "\n",
    "Triggering our graph via new request\n",
    "\n",
    "We'll use `astream` context manager to iterate through each step of graph workflow and log some useful info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3oo8E-PRK1T",
    "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DM5WJkd3CFSBmOHb21Y3kgT3', 'function': {'arguments': '{\"query\": \"LoRA machine learning\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_p8T4v46FjWjZl2m9aOmSUctX', 'function': {'arguments': '{\"query\": \"Tim Dettmers\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_Lpnq48zNPlAPqsrCZS9Kdjb3', 'function': {'arguments': '{\"query\": \"Attention mechanism in machine learning\"}', 'name': 'arxiv'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 177, 'total_tokens': 250, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d1cd4f8a-1939-4b71-978b-7e7846b792df-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'LoRA machine learning'}, 'id': 'call_DM5WJkd3CFSBmOHb21Y3kgT3', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Tim Dettmers'}, 'id': 'call_p8T4v46FjWjZl2m9aOmSUctX', 'type': 'tool_call'}, {'name': 'arxiv', 'args': {'query': 'Attention mechanism in machine learning'}, 'id': 'call_Lpnq48zNPlAPqsrCZS9Kdjb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 73, 'total_tokens': 250, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "[ToolMessage(content=\"Published: 2024-10-25\\nTitle: Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead\\nAuthors: Rickard Br√ºel-Gabrielsson, Jiacheng Zhu, Onkar Bhardwaj, Leshem Choshen, Kristjan Greenewald, Mikhail Yurochkin, Justin Solomon\\nSummary: Fine-tuning large language models (LLMs) with low-rank adaptations (LoRAs)\\nhas become common practice, often yielding numerous copies of the same LLM\\ndiffering only in their LoRA updates. This paradigm presents challenges for\\nsystems that serve real-time responses to queries that each involve a different\\nLoRA. Prior works optimize the design of such systems but still require\\ncontinuous loading and offloading of LoRAs, as it is infeasible to store\\nthousands of LoRAs in GPU memory. To mitigate this issue, we investigate the\\nefficacy of model compression when serving LoRAs. We propose a method for joint\\ncompression of LoRAs into a shared basis paired with LoRA-specific scaling\\nmatrices. We extend our algorithm to learn clusters of LoRAs that are more\\namenable to joint compression, allowing it to scale gracefully to large LoRA\\ncollections. Our experiments with up to 500 LoRAs demonstrate that compressed\\nLoRAs preserve performance while offering major throughput gains in realistic\\nserving scenarios with over a thousand LoRAs, maintaining 80% of the throughput\\nof serving a single LoRA.\\n\\nPublished: 2024-10-28\\nTitle: KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation\\nAuthors: Rambod Azimi, Rishav Rishav, Marek Teichmann, Samira Ebrahimi Kahou\\nSummary: Large language models (LLMs) have demonstrated remarkable performance across\\nvarious downstream tasks. However, the high computational and memory\\nrequirements of LLMs are a major bottleneck. To address this,\\nparameter-efficient fine-tuning (PEFT) methods such as low-rank adaptation\\n(LoRA) have been proposed to reduce computational costs while ensuring minimal\\nloss in performance. Additionally, knowledge distillation (KD) has been a\\npopular choice for obtaining compact student models from teacher models. In\\nthis work, we present KD-LoRA, a novel fine-tuning method that combines LoRA\\nwith KD. Our results demonstrate that KD-LoRA achieves performance comparable\\nto full fine-tuning (FFT) and LoRA while significantly reducing resource\\nrequirements. Specifically, KD-LoRA retains 98% of LoRA's performance on the\\nGLUE benchmark, while being 40% more compact. Additionally, KD-LoRA reduces GPU\\nmemory usage by 30% compared to LoRA, while decreasing inference time by 30%\\ncompared to both FFT and LoRA. We evaluate KD-LoRA across three encoder-only\\nmodels: BERT, RoBERTa, and DeBERTaV3. Code is available at\\nhttps://github.com/rambodazimi/KD-LoRA.\\n\\nPublished: 2024-04-07\\nTitle: A Note on LoRA\\nAuthors: Vlad Fomenko, Han Yu, Jongho Lee, Stanley Hsieh, Weizhu Chen\\nSummary: LoRA (Low-Rank Adaptation) has emerged as a preferred method for efficiently\\nadapting Large Language Models (LLMs) with remarkable simplicity and efficacy.\\nThis note extends the original LoRA paper by offering new perspectives that\\nwere not initially discussed and presents a series of insights for deploying\\nLoRA at scale. Without introducing new experiments, we aim to improve the\\nunderstanding and application of LoRA.\", name='arxiv', id='ed8b4ce0-778c-46f0-b4e0-4d403e279758', tool_call_id='call_DM5WJkd3CFSBmOHb21Y3kgT3'), ToolMessage(content='[{\"url\": \"https://timdettmers.com/about/\", \"content\": \"Tim Dettmers is a research scientist at Ai2 and an incoming assistant professor at CMU. He works on efficient deep learning methods, such as quantization, sparsity, and low-bit inference.\"}, {\"url\": \"https://timdettmers.com/\", \"content\": \"Tim Dettmers is a researcher and teacher in deep learning and natural language processing. His blog covers topics such as hardware, quantization, sparse networks, creativity, and grad school choices.\"}, {\"url\": \"https://ai2050.schmidtsciences.org/fellow/tim-dettmers/\", \"content\": \"Tim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI, and his research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. AI models like ChatGPT work well for general use but fail in specialized expert domains, such as the medical sciences. To make AI models work in expert domains, one must adapt them, which is costly and requires significant AI expertise. This project overcomes these cost and expertise barriers through two new approaches: (1) use AI models themselves to perform the AI model adaptation process automatically; (2) make the adaptation process cheap so it can be run on regular consumer hardware.\"}, {\"url\": \"https://developer.nvidia.com/blog/author/tdettmers/\", \"content\": \"Tim Dettmers is a masters student in informatics at the University of Lugano where he works on deep learning research. Before that he studied applied mathematics and worked for three years as a software engineer in the automation industry.\"}, {\"url\": \"https://tech.cornell.edu/events/seminar-cornell-tech-tim-dettmers/\", \"content\": \"Jacobs Technion-Cornell Dual MS Degrees ‚Äì Health Tech Concentration Jacobs Technion-Cornell Dual MS Degrees ‚Äì Urban Tech Concentration Cornell Tech Impact Study Jacobs Technion-Cornell Dual MS Degrees ‚Äì Urban Tech Concentration Cornell Tech Impact Study Seminar @ Cornell Tech: Tim Dettmers Research Events, Seminar @ Cornell Tech, Master\\'s Students, PhDs, Postdocs In this talk, Tim Dettmers will present research that significantly lowers these barriers for a wide range of use cases, including inference algorithms that are used to make predictions after training, finetuning approaches that adapt a trained model to new data, and finally, full training of foundation models from scratch. Tim Dettmers‚Äôs research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements.\"}]', name='tavily_search_results_json', id='9c8c04f6-ee46-40e7-86b3-da65818fe002', tool_call_id='call_p8T4v46FjWjZl2m9aOmSUctX', artifact={'query': 'Tim Dettmers', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'About Me ‚Äî Tim Dettmers', 'url': 'https://timdettmers.com/about/', 'content': 'Tim Dettmers is a research scientist at Ai2 and an incoming assistant professor at CMU. He works on efficient deep learning methods, such as quantization, sparsity, and low-bit inference.', 'score': 0.9407083, 'raw_content': None}, {'title': 'Tim Dettmers ‚Äî Making deep learning accessible.', 'url': 'https://timdettmers.com/', 'content': 'Tim Dettmers is a researcher and teacher in deep learning and natural language processing. His blog covers topics such as hardware, quantization, sparse networks, creativity, and grad school choices.', 'score': 0.9405774, 'raw_content': None}, {'title': 'Tim Dettmers - AI2050', 'url': 'https://ai2050.schmidtsciences.org/fellow/tim-dettmers/', 'content': 'Tim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI, and his research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. AI models like ChatGPT work well for general use but fail in specialized expert domains, such as the medical sciences. To make AI models work in expert domains, one must adapt them, which is costly and requires significant AI expertise. This project overcomes these cost and expertise barriers through two new approaches: (1) use AI models themselves to perform the AI model adaptation process automatically; (2) make the adaptation process cheap so it can be run on regular consumer hardware.', 'score': 0.9263638, 'raw_content': None}, {'title': 'Author: Tim Dettmers | NVIDIA Technical Blog - NVIDIA Developer', 'url': 'https://developer.nvidia.com/blog/author/tdettmers/', 'content': 'Tim Dettmers is a masters student in informatics at the University of Lugano where he works on deep learning research. Before that he studied applied mathematics and worked for three years as a software engineer in the automation industry.', 'score': 0.9170729, 'raw_content': None}, {'title': 'Seminar @ Cornell Tech: Tim Dettmers', 'url': 'https://tech.cornell.edu/events/seminar-cornell-tech-tim-dettmers/', 'content': \"Jacobs Technion-Cornell Dual MS Degrees ‚Äì Health Tech Concentration Jacobs Technion-Cornell Dual MS Degrees ‚Äì Urban Tech Concentration Cornell Tech Impact Study Jacobs Technion-Cornell Dual MS Degrees ‚Äì Urban Tech Concentration Cornell Tech Impact Study Seminar @ Cornell Tech: Tim Dettmers Research Events, Seminar @ Cornell Tech, Master's Students, PhDs, Postdocs In this talk, Tim Dettmers will present research that significantly lowers these barriers for a wide range of use cases, including inference algorithms that are used to make predictions after training, finetuning approaches that adapt a trained model to new data, and finally, full training of foundation models from scratch. Tim Dettmers‚Äôs research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements.\", 'score': 0.7574541, 'raw_content': None}], 'response_time': 1.68}), ToolMessage(content='Published: 2022-03-27\\nTitle: A General Survey on Attention Mechanisms in Deep Learning\\nAuthors: Gianni Brauwers, Flavius Frasincar\\nSummary: Attention is an important mechanism that can be employed for a variety of\\ndeep learning models across many different domains and tasks. This survey\\nprovides an overview of the most important attention mechanisms proposed in the\\nliterature. The various attention mechanisms are explained by means of a\\nframework consisting of a general attention model, uniform notation, and a\\ncomprehensive taxonomy of attention mechanisms. Furthermore, the various\\nmeasures for evaluating attention models are reviewed, and methods to\\ncharacterize the structure of attention models based on the proposed framework\\nare discussed. Last, future work in the field of attention models is\\nconsidered.\\n\\nPublished: 2022-07-04\\nTitle: Attention mechanisms for physiological signal deep learning: which attention should we take?\\nAuthors: Seong-A Park, Hyung-Chul Lee, Chul-Woo Jung, Hyun-Lim Yang\\nSummary: Attention mechanisms are widely used to dramatically improve deep learning\\nmodel performance in various fields. However, their general ability to improve\\nthe performance of physiological signal deep learning model is immature. In\\nthis study, we experimentally analyze four attention mechanisms (e.g.,\\nsqueeze-and-excitation, non-local, convolutional block attention module, and\\nmulti-head self-attention) and three convolutional neural network (CNN)\\narchitectures (e.g., VGG, ResNet, and Inception) for two representative\\nphysiological signal prediction tasks: the classification for predicting\\nhypotension and the regression for predicting cardiac output (CO). We evaluated\\nmultiple combinations for performance and convergence of physiological signal\\ndeep learning model. Accordingly, the CNN models with the spatial attention\\nmechanism showed the best performance in the classification problem, whereas\\nthe channel attention mechanism achieved the lowest error in the regression\\nproblem. Moreover, the performance and convergence of the CNN models with\\nattention mechanisms were better than stand-alone self-attention models in both\\nproblems. Hence, we verified that convolutional operation and attention\\nmechanisms are complementary and provide faster convergence time, despite the\\nstand-alone self-attention models requiring fewer parameters.\\n\\nPublished: 2018-10-17\\nTitle: An Analysis of Attention Mechanisms: The Case of Word Sense Disambiguation in Neural Machine Translation\\nAuthors: Gongbo Tang, Rico Sennrich, Joakim Nivre\\nSummary: Recent work has shown that the encoder-decoder attention mechanisms in neural\\nmachine translation (NMT) are different from the word alignment in statistical\\nmachine translation. In this paper, we focus on analyzing encoder-decoder\\nattention mechanisms, in the case of word sense disambiguation (WSD) in NMT\\nmodels. We hypothesize that attention mechanisms pay more attention to context\\ntokens when translating ambiguous words. We explore the attention distribution\\npatterns when translating ambiguous nouns. Counter-intuitively, we find that\\nattention mechanisms are likely to distribute more attention to the ambiguous\\nnoun itself rather than context tokens, in comparison to other nouns. We\\nconclude that attention mechanism is not the main mechanism used by NMT models\\nto incorporate contextual information for WSD. The experimental results suggest\\nthat NMT models learn to encode contextual information necessary for WSD in the\\nencoder hidden states. For the attention mechanism in Transformer models, we\\nreveal that the first few layers gradually learn to \"align\" source and target\\ntokens and the last few layers learn to extract features from the related but\\nunaligned context tokens.', name='arxiv', id='716b6a31-c998-40fe-bda9-31747f288731', tool_call_id='call_Lpnq48zNPlAPqsrCZS9Kdjb3')]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='### What is LoRA?\\n\\nLoRA, or Low-Rank Adaptation, is a technique used in machine learning, particularly for fine-tuning large language models (LLMs). It allows for efficient adaptation of these models by introducing low-rank updates to the model parameters, which significantly reduces the computational and memory requirements associated with traditional fine-tuning methods. Recent research has explored various aspects of LoRA, including methods for compressing multiple LoRA adapters for efficient serving and hybrid approaches that combine LoRA with knowledge distillation to further enhance performance while minimizing resource usage.\\n\\n### Who is Tim Dettmers?\\n\\nTim Dettmers is a research scientist at the Allen Institute for AI and an incoming assistant professor at Carnegie Mellon University (CMU). His research focuses on efficient deep learning methods, including quantization, sparsity, and low-bit inference. He aims to make foundation models, such as ChatGPT, more accessible by reducing their resource requirements, particularly for specialized applications in expert domains like medical sciences. Dettmers is also known for his contributions to making AI model adaptation processes more efficient and less resource-intensive.\\n\\n### What is Attention?\\n\\nAttention is a mechanism widely used in deep learning models, particularly in natural language processing and computer vision. It allows models to focus on specific parts of the input data when making predictions, effectively weighing the importance of different elements. Various attention mechanisms have been proposed, each with its own strengths and applications. For instance, attention mechanisms can improve model performance in tasks like machine translation, image captioning, and physiological signal analysis. They help models learn to prioritize relevant information, enhancing their ability to understand context and make accurate predictions.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 332, 'prompt_tokens': 2362, 'total_tokens': 2694, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-99c19a09-efcf-4c0c-9e40-c31b03d2f92f-0', usage_metadata={'input_tokens': 2362, 'output_tokens': 332, 'total_tokens': 2694, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"Related to machine learning, what is LoRA? Also, who is Tim Dettmers? Also, what is Attention?\")]}\n",
    "\n",
    "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVmZPs6lnpsM"
   },
   "source": [
    "### Task 4: LangGraph for the \"Patterns\" of GenAI\n",
    "\n",
    "Let's ask our system about the 4 patterns of Generative AI:\n",
    "\n",
    "1. Prompt Engineering\n",
    "2. RAG\n",
    "3. Fine-tuning\n",
    "4. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ZoLl7GlXoae-"
   },
   "outputs": [],
   "source": [
    "patterns = [\"prompt engineering\", \"RAG\", \"fine-tuning\", \"LLM-based agents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zkh0YJuCp3Zl",
    "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### What is Prompt Engineering?\n",
      "\n",
      "Prompt engineering is the process of crafting effective prompts to guide AI models in generating desired responses based on given inputs. It involves using descriptive and meaningful prompts in natural language to optimize the performance of generative AI tools. This technique is crucial in various applications, including natural language processing (NLP), translation, chatbots, and more. \n",
      "\n",
      "Key techniques in prompt engineering include:\n",
      "- **Zero-Shot Prompting**: Asking the AI to perform a task without prior examples.\n",
      "- **Chain-of-Thought Prompting**: Breaking down tasks into smaller steps to guide the AI through a logical progression.\n",
      "\n",
      "Prompt engineering has become essential for maximizing the capabilities of large language models without the need for extensive retraining. It encompasses a range of strategies, from few-shot learning to iterative refinement, enabling prompt engineers to elicit reliable and compelling results from AI models. [Learn more here](https://www.geeksforgeeks.org/what-is-prompt-engineering-the-ai-revolution/).\n",
      "\n",
      "### When Did Prompt Engineering Become Popular?\n",
      "\n",
      "Prompt engineering has gained significant attention and importance in recent years, particularly with the rise of advanced AI models and their applications in various fields. While the concept of designing effective prompts has existed for some time, its prominence surged during the AI revolution, especially with the advent of powerful language models like GPT-3 and others.\n",
      "\n",
      "The role of prompt engineers has been highlighted in discussions about the future of work and AI's impact on various industries. Events like the World Economic Forum have recognized prompt engineering as a growing field, emphasizing its importance in the development of conversational AI and human-computer interfaces. \n",
      "\n",
      "Overall, prompt engineering has become a critical skill in the age of AI, evolving alongside advancements in technology and the increasing demand for effective AI interactions. [Read more about its history and significance here](https://promptly.substack.com/p/a-journey-through-the-history-of).\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pattern in patterns:\n",
    "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
    "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
    "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
    "  print(messages[\"messages\"][-1].content)\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041e22a9b5514e36bd4d1dac01d5d398": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d622ccc56264fac8fd7508dbdbe6e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53e33aae3b97490c82aec7bbb0d6ebba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_041e22a9b5514e36bd4d1dac01d5d398",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_886d762f2a7c421382efb5502c6d42a1",
      "value": ""
     }
    },
    "716557ad09874dcb989d75f7c74424cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72adef9b70dd48198b7322b6c5b113cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77d4c0ebaae045b58efc4f789c9a2360",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0d622ccc56264fac8fd7508dbdbe6e29",
      "value": "‚Äá6/?‚Äá[00:36&lt;00:00,‚Äá‚Äá5.78s/it]"
     }
    },
    "77d4c0ebaae045b58efc4f789c9a2360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "886d762f2a7c421382efb5502c6d42a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a61d045ffd44ac58f3f13eb10044836": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab91fd625bbd43afbf8c6398193a88d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ad84e0e971d3455db2efe7dd0d1f803e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab91fd625bbd43afbf8c6398193a88d0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_716557ad09874dcb989d75f7c74424cd",
      "value": 1
     }
    },
    "efcf57067cf743d8b4ce059a61cbe02e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53e33aae3b97490c82aec7bbb0d6ebba",
       "IPY_MODEL_ad84e0e971d3455db2efe7dd0d1f803e",
       "IPY_MODEL_72adef9b70dd48198b7322b6c5b113cf"
      ],
      "layout": "IPY_MODEL_8a61d045ffd44ac58f3f13eb10044836"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
